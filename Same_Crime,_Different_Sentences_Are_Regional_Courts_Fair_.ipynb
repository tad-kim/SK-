
        "    shutil.rmtree(mpl.get_cachedir())\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Matplotlib 전역 강제: family + sans-serif 리스트 모두 고정\n",
        "mpl.rcParams.update({\n",
        "    \"font.family\": [FONT_NAME],                \n",
        "    \"font.sans-serif\": [FONT_NAME, \"Malgun Gothic\", \"Noto Sans CJK KR\", \"Apple SD Gothic Neo\", \"DejaVu Sans\"],\n",
        "    \"axes.unicode_minus\": False\n",
        "})\n",
        "\n",
        "# Seaborn 테마 적용하면서 rc 다시 덮어쓰기\n",
        "sns.set_theme(rc={\n",
        "    \"font.family\": [FONT_NAME],\n",
        "    \"font.sans-serif\": [FONT_NAME, \"Malgun Gothic\", \"Noto Sans CJK KR\", \"Apple SD Gothic Neo\", \"DejaVu Sans\"],\n",
        "    \"axes.unicode_minus\": False\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSRbio-0NNlj",
        "outputId": "5cdf9561-55c1-4bd6-b238-73782723eec0"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------- 본문 정규화\n",
        "\n",
        "normalize_map = {'\\u00A0': ' ', '\\u200b': '', '\\ufeff': '', '\\r': '', 'ㆍ': '·'}\n",
        "norm = df['본문'].fillna('').astype(str)\n",
        "norm = norm.replace(normalize_map, regex=False)\n",
        "norm = norm.str.replace(r'<br\\s*/?>', '\\n', regex=True)\n",
        "norm = norm.str.replace(r'<[^>]+>', ' ', regex=True)\n",
        "norm = norm.str.replace(r'\\(주문\\)|\\[주문\\]', ' 주문 ', regex=True)\n",
        "norm = norm.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "df['본문_정규화'] = norm\n",
        "\n",
        "txt = df['본문_정규화']\n",
        "\n",
        "# -----------------------------------------------------벌금/금액 파싱 \n",
        "\n",
        "def parse_money_kr(s):\n",
        "    if not isinstance(s, str): return 0\n",
        "    s = s.replace(',', '')\n",
        "    pat_list = [\n",
        "        (r'(?:벌금|일금)\\s*금?\\s*([0-9]+(?:\\.[0-9]+)?)\\s*(?:원(?:정)?)(?:에\\s*상당(?:하는)?)?', 1),\n",
        "        (r'(?:벌금|일금)\\s*금?\\s*([0-9]+(?:\\.[0-9]+)?)\\s*만\\s*(?:원(?:정)?)(?:에\\s*상당(?:하는)?)?', 10_000),\n",
        "        (r'(?:벌금|일금)\\s*금?\\s*([0-9]+(?:\\.[0-9]+)?)\\s*백\\s*만\\s*(?:원(?:정)?)(?:에\\s*상당(?:하는)?)?', 1_000_000),\n",
        "        (r'(?:벌금|일금)\\s*금?\\s*([0-9]+(?:\\.[0-9]+)?)\\s*천\\s*만\\s*(?:원(?:정)?)(?:에\\s*상당(?:하는)?)?', 10_000_000),\n",
        "        (r'(?:벌금|일금)\\s*금?\\s*([0-9]+(?:\\.[0-9]+)?)\\s*억\\s*(?:원(?:정)?)(?:에\\s*상당(?:하는)?)?', 100_000_000),\n",
        "    ]\n",
        "    found = []\n",
        "    for pat, mul in pat_list:\n",
        "        for num in re.findall(pat, s):\n",
        "            try: found.append(int(float(num) * mul))\n",
        "            except: pass\n",
        "    return max(found) if found else 0\n",
        "\n",
        "def parse_amount_generic(s, head_words, unit_mul):\n",
        "    if not isinstance(s, str): return 0\n",
        "    s = s.replace(',', '')\n",
        "    found = []\n",
        "    for pat, mul in unit_mul:\n",
        "        p = rf'(?:{\"|\".join(head_words)})\\s*([0-9]+(?:\\.[0-9]+)?)\\s*{pat}'\n",
        "        for num in re.findall(p, s):\n",
        "            try: found.append(int(float(num)*mul))\n",
        "            except: pass\n",
        "    return max(found) if found else 0\n",
        "\n",
        "UNIT_PAT = [\n",
        "    (r'원(?:정)?', 1), (r'만\\s*원(?:정)?', 10_000), (r'백\\s*만\\s*원(?:정)?', 1_000_000),\n",
        "    (r'천\\s*만\\s*원(?:정)?', 10_000_000), (r'억\\s*원(?:정)?', 100_000_000),\n",
        "]\n",
        "df['추징금_원'] = df['본문_정규화'].apply(lambda s: parse_amount_generic(s, ['추징금'], UNIT_PAT))\n",
        "df['과태료_원'] = df['본문_정규화'].apply(lambda s: parse_amount_generic(s, ['과태료'], UNIT_PAT))\n",
        "df['벌금_원'] = df['본문_정규화'].apply(parse_money_kr).fillna(0).astype(int)\n",
        "df['벌금_문구플래그'] = txt.str.contains(r'벌금(?:에|형[에을]?)(?:\\s*처|선고)', na=False)\n",
        "df['벌금형확인여부'] = (df['벌금_원'] > 0) | df['벌금_문구플래그']\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------판사명/초범·재범\n",
        "\n",
        "pat_judge_any = (\n",
        "    r'(?:수석부장|부장|재판장|단독|합의부|주심|배석|수명법관|직무대리|대법관|주심대법관)?\\s*'\n",
        "    r'([가-힣]{2,3}|[가-힣]○{1,2})\\s*(?:판사|재판장|대법관)'\n",
        ")\n",
        "candA = txt.str.extract(pat_judge_any)[0]\n",
        "candB = txt.str.extract(r'(?:판사|재판장)\\s*([가-힣]{2,3}|[가-힣]○{1,2})')[0]\n",
        "candC = txt.str.extract(r'([가-힣]{2,3}|[가-힣]○{1,2})\\s*(?:판사|재판장)')[0]\n",
        "df['판사명'] = candA.fillna(candB).fillna(candC).fillna('판사미상')\n",
        "\n",
        "neg_more = txt.str.contains(r'(?:전과\\s*(?:있|多|여러|수회)|초범이\\s*아니)', na=False)\n",
        "df['초범여부'] = (txt.str.contains(r'초범|전과\\s*없|무전과', na=False)) & (~neg_more)\n",
        "df['재범여부'] = txt.str.contains(r'누범|재범|상습|동종전과', na=False)\n",
        "\n",
        "# -----------------------------------------------------------강력범죄\n",
        "\n",
        "strong_crimes = ['살인','사기','성폭행','강간','강도','강제추행','상해','폭행']\n",
        "df['강력범죄여부'] = df['매칭키워드_유니크'].apply(\n",
        "    lambda x: any(k in x for k in strong_crimes) if isinstance(x, list) else False\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------본문 법령/조항 추출\n",
        "\n",
        "name_map = {\n",
        "    '형법':'형법','형사소송법':'형사소송법','근로기준법':'근로기준법','산업안전보건법':'산업안전보건법',\n",
        "    '중대재해처벌법':'중대재해처벌법','산업재해보상보험법':'산재보상보험법','공정거래법':'독점규제및공정거래에관한법률',\n",
        "    '도로교통법':'도로교통법','민법':'민법','민사소송법':'민사소송법',\n",
        "    '성폭력범죄의처벌등에관한특례법':'성폭력처벌법','아동·청소년의 성보호에 관한 법률':'아청법',\n",
        "    '특정범죄 가중처벌 등에 관한 법률':'특정범죄가중처벌법','정보통신망법':'정보통신망법',\n",
        "    '개인정보보호법':'개인정보보호법','마약류관리에관한법률':'마약류관리에관한법률',\n",
        "    '식품위생법':'식품위생법','전자금융거래법':'전자금융거래법','전기통신사업법':'전기통신사업법','병역법':'병역법',\n",
        "}\n",
        "law_pat = (\n",
        "    r'(형법|형사소송법|민법|민사소송법|근로기준법|산업안전보건법|중대재해처벌법|'\n",
        "    r'산업재해보상보험법|공정거래법|도로교통법|성폭력범죄의처벌등에관한특례법|'\n",
        "    r'아동[·\\.]청소년의\\s*성보호에\\s*관한\\s*법률|특정범죄\\s*가중처벌\\s*등에\\s*관한\\s*법률|'\n",
        "    r'정보통신망법|개인정보보호법|마약류관리에관한법률|식품위생법|전자금융거래법|전기통신사업법|병역법)'\n",
        ")\n",
        "law_re = re.compile(law_pat)\n",
        "art_re = re.compile(r'제\\s*(\\d+)(?:조(?:의(\\d+))?)?(?:\\s*제\\s*(\\d+)항)?(?:\\s*제\\s*(\\d+)호)?')\n",
        "\n",
        "def propagate_lawnames(text):\n",
        "    if not isinstance(text, str): return []\n",
        "    paras = re.split(r'\\n\\s*\\n+', text)\n",
        "    hits = []\n",
        "    for para in paras:\n",
        "        last_law = None\n",
        "        for sent in re.split(r'(?<=[\\.\\!\\?]|\\n)\\s+', para):\n",
        "            for m in law_re.finditer(sent):\n",
        "                last_law = m.group(1)\n",
        "            for m in art_re.finditer(sent):\n",
        "                jo, jo_ui, hang, ho = m.group(1), m.group(2), m.group(3), m.group(4)\n",
        "                jo_norm = f\"{jo}-{jo_ui}\" if jo_ui else jo\n",
        "                hits.append({'law': last_law, 'article': jo_norm, 'hang': hang, 'ho': ho, 'raw': m.group(0)})\n",
        "    return hits\n",
        "\n",
        "# 인용법령_리스트 존재 보장\n",
        "if '인용법령_리스트' not in df.columns:\n",
        "    df['인용법령_리스트'] = pd.Series([[] for _ in range(len(df))], index=df.index, dtype='object')\n",
        "else:\n",
        "    def _to_list(v):\n",
        "        if isinstance(v, list): return v\n",
        "        if isinstance(v, dict): return [v]\n",
        "        if pd.isna(v): return []\n",
        "        if isinstance(v, str):\n",
        "            try:\n",
        "                p = json.loads(v)\n",
        "                if isinstance(p, list): return p\n",
        "                if isinstance(p, dict): return [p]\n",
        "            except: return []\n",
        "        return []\n",
        "    df['인용법령_리스트'] = df['인용법령_리스트'].apply(_to_list).astype('object')\n",
        "\n",
        "# 기존 인용 + 전파 인용 병합 후 표준화\n",
        "merged_hits = []\n",
        "for base, text in zip(df['인용법령_리스트'], df['본문_정규화']):\n",
        "    base = base if isinstance(base, list) else []\n",
        "    prop = propagate_lawnames(text)\n",
        "    dedup = {}\n",
        "    for h in (base + prop):\n",
        "        key = f\"{h.get('law','')}|{h.get('article','')}|{h.get('hang','')}|{h.get('ho','')}\"\n",
        "        dedup[key] = {\n",
        "            'law': h.get('law',''), 'article': h.get('article',''),\n",
        "            'hang': h.get('hang',''), 'ho': h.get('ho',''), 'raw': h.get('raw','')\n",
        "        }\n",
        "    merged_hits.append(list(dedup.values()))\n",
        "df['인용법령_리스트'] = pd.Series(merged_hits, index=df.index, dtype='object')\n",
        "\n",
        "def _norm_name(x): return name_map.get(x, x) if isinstance(x, str) else x\n",
        "df['인용법령_리스트'] = [\n",
        "    [{**h, 'law': _norm_name(h.get('law'))} for h in hits] for hits in df['인용법령_리스트']\n",
        "]\n",
        "\n",
        "# ---------------------------------------------------------------형량/집행유예/형종\n",
        "\n",
        "def months_from_match(ms):\n",
        "    if not ms: return 0\n",
        "    cand = []\n",
        "    for *vals, in ms:\n",
        "        y = int((vals[0] or 0)); m = int((vals[1] or 0)); d = int((vals[2] or 0)) if len(vals) > 2 else 0\n",
        "        total = y*12 + m + (d/30)\n",
        "        cand.append(int(round(total)))\n",
        "    return max(cand, default=0)\n",
        "\n",
        "re_j = re.compile(r'(?:징역형|징역)\\s*(?:(\\d+)\\s*년)?\\s*(?:(\\d+)\\s*개월?|월)?\\s*(?:(\\d+)\\s*일\\s*간?)?')\n",
        "re_g = re.compile(r'(?:금고형|금고)\\s*(?:(\\d+)\\s*년)?\\s*(?:(\\d+)\\s*개월?|월)?\\s*(?:(\\d+)\\s*일\\s*간?)?')\n",
        "re_sus = re.compile(r'집행유예\\s*(?:(\\d+)\\s*년)?\\s*(?:(\\d+)\\s*월)?')\n",
        "re_sus_alt = re.compile(\n",
        "    r'(?:징역형의\\s*)?형(?:의)?\\s*집행(?:을)?\\s*(?:(\\d+)\\s*년)?\\s*(?:(\\d+)\\s*월)?\\s*(?:간|기간)?\\s*유예(?:한다|함)?'\n",
        ")\n",
        "\n",
        "df['징역_월'] = txt.str.findall(re_j).apply(months_from_match).astype(int)\n",
        "df['금고_월'] = txt.str.findall(re_g).apply(months_from_match).astype(int)\n",
        "df['집행유예'] = np.maximum(\n",
        "    txt.str.findall(re_sus).apply(months_from_match).astype(int),\n",
        "    txt.str.findall(re_sus_alt).apply(months_from_match).astype(int)\n",
        ")\n",
        "\n",
        "# 장단기 평균 반영\n",
        "re_ls_any = [\n",
        "    r'징역\\s*장기\\s*(\\d+)\\s*년(?:\\s*(\\d+)\\s*월)?\\s*단기\\s*(\\d+)\\s*년(?:\\s*(\\d+)\\s*월)?',\n",
        "    r'징역\\s*(\\d+)\\s*년(?:\\s*(\\d+)\\s*월)?\\s*~\\s*(\\d+)\\s*년(?:\\s*(\\d+)\\s*월)?'\n",
        "]\n",
        "def extract_ls_months(series):\n",
        "    s = series.astype(str)\n",
        "    out = pd.Series(0, index=s.index, dtype='Int64')\n",
        "    frames = []\n",
        "    for pat in re_ls_any:\n",
        "        m = s.str.extract(pat)\n",
        "        if m.shape[1] != 4: continue\n",
        "        m = m.rename(columns={0:'y1',1:'m1',2:'y2',3:'m2'})\n",
        "        for c in ['y1','m1','y2','m2']:\n",
        "            m[c] = pd.to_numeric(m[c], errors='coerce').fillna(0).astype(int)\n",
        "        a = m['y1']*12 + m['m1']; b = m['y2']*12 + m['m2']\n",
        "        avg = ((a + b) / 2).round().astype('Int64')\n",
        "        frames.append(avg.rename(f\"avg_{len(frames)}\"))\n",
        "    if frames:\n",
        "        cand = pd.concat(frames, axis=1)\n",
        "        out = cand.max(axis=1).astype('Int64').fillna(0).astype('Int64')\n",
        "    return out\n",
        "\n",
        "df['징역_월'] = np.maximum(df['징역_월'], extract_ls_months(txt)).fillna(0).astype(int)\n",
        "df['집행유예_여부'] = df['집행유예'] > 0\n",
        "df['실형확인여부'] = (~df['집행유예_여부']) & ((df['징역_월'] + df['금고_월']) > 0)\n",
        "df['실형_월'] = np.where(df['집행유예_여부'], 0, np.maximum(df['징역_월'], df['금고_월']))\n",
        "df['형량_월_기준'] = df['실형_월']\n",
        "\n",
        "not_law = txt.str.contains(r'무죄', na=False)\n",
        "df['형종'] = np.select(\n",
        "    [not_law, df['징역_월'].gt(0), df['금고_월'].gt(0), df['벌금_원'].gt(0)],\n",
        "    ['무죄', '징역', '금고', '벌금'], default='불명'\n",
        ")\n",
        "\n",
        "\n",
        "for c in ['징역_월','금고_월','집행유예','벌금_원','총형량_월','실형_월','형량_월_기준']:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# -----------------------------------------------------------------범죄키워드\n",
        "\n",
        "try:\n",
        "    base_kw = KW_SOCIAL + KW_CRIME  \n",
        "except NameError:\n",
        "    base_kw = []\n",
        "\n",
        "CRIME_KEYWORDS = list(dict.fromkeys(base_kw + [\n",
        "    '살인','강간','강제추행','성폭행','강도','사기','횡령','배임','절도','상해','폭행',\n",
        "    '명예훼손','모욕','도박','방화','마약','음주운전','무면허운전','전자금융','피싱','개인정보',\n",
        "    '정보통신망','공갈','손괴','문서위조','공정거래','식품위생','병역','교통사고'\n",
        "]))\n",
        "\n",
        "def extract_crime_list(text: str):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    \n",
        "    return [kw for kw in CRIME_KEYWORDS if kw in text][:5]\n",
        "\n",
        "def sget(col): \n",
        "    return df[col] if col in df.columns else pd.Series(['']*len(df), index=df.index)\n",
        "\n",
        "src_text = (sget('사건명').fillna('').astype(str) + ' ' +\n",
        "            df['본문_정규화'].fillna(''))\n",
        "\n",
        "df['범죄키워드_리스트'] = src_text.apply(extract_crime_list).astype('object')\n",
        "\n",
        "# -----------------------------------------------------------선고유형 파생\n",
        "\n",
        "df['선고유형'] = np.select(\n",
        "    [df['실형확인여부'], df['집행유예_여부'], df['벌금형확인여부'], df['형종'].eq('무죄')],\n",
        "    ['실형','집행유예','벌금','무죄'], default='기타'\n",
        ")\n",
        "mask_etc = df['선고유형'].eq('기타')\n",
        "txt_etc = df.loc[mask_etc, '본문_정규화'].fillna('')\n",
        "df.loc[mask_etc, '기타_세분류'] = np.select(\n",
        "    [\n",
        "        txt_etc.str.contains(r'선고유예', na=False),\n",
        "        txt_etc.str.contains(r'공소기각|각하|취소', na=False),\n",
        "        txt_etc.str.contains(r'형면제|선고면제', na=False),\n",
        "        txt_etc.str.contains(r'사회봉사|수강명령|보호관찰', na=False),\n",
        "        txt_etc.str.contains(r'약식명령|약식기각', na=False)\n",
        "    ],\n",
        "    ['선고유예','공소기각/각하','형면제','보호처분','약식'], default='불명확'\n",
        ")\n",
        "sent_order = ['실형','집행유예','벌금','무죄','약식','선고유예','보호처분','공소기각/각하','불명확']\n",
        "df['선고유형_확장'] = np.where(df['선고유형'].eq('기타'), df['기타_세분류'], df['선고유형'])\n",
        "df['선고유형_확장'] = pd.Categorical(df['선고유형_확장'], categories=sent_order, ordered=True)\n",
        "\n",
        "# '불명확' 세부 재분류\n",
        "mask_unknown = df['선고유형_확장'].astype(str).eq('불명확')\n",
        "txt_unknown = df.loc[mask_unknown, '본문_정규화'].fillna('')\n",
        "df.loc[mask_unknown, '불명확_재분류'] = np.select(\n",
        "    [\n",
        "        txt_unknown.str.contains(r'선고유예', na=False),\n",
        "        txt_unknown.str.contains(r'공소기각|각하|취소', na=False),\n",
        "        txt_unknown.str.contains(r'형면제|선고면제', na=False),\n",
        "        txt_unknown.str.contains(r'사회봉사|수강명령|보호관찰', na=False),\n",
        "        txt_unknown.str.contains(r'약식명령|약식기각', na=False),\n",
        "        txt_unknown.str.contains(r'벌금', na=False),\n",
        "        txt_unknown.str.contains(r'징역|금고', na=False)\n",
        "    ],\n",
        "    ['선고유예','공소기각/각하','형면제','보호처분','약식','벌금','실형'], default='진짜불명확'\n",
        ")\n",
        "\n",
        "if not isinstance(df['선고유형_확장'].dtype, pd.CategoricalDtype):\n",
        "    df['선고유형_확장'] = pd.Categorical(df['선고유형_확장'], categories=sent_order, ordered=True)\n",
        "new_vals = pd.Index(df.loc[mask_unknown, '불명확_재분류'].dropna().unique())\n",
        "missing = new_vals.difference(df['선고유형_확장'].cat.categories)\n",
        "if len(missing):\n",
        "    df['선고유형_확장'] = df['선고유형_확장'].cat.add_categories(missing)\n",
        "df.loc[mask_unknown, '선고유형_확장'] = df.loc[mask_unknown, '불명확_재분류']\n",
        "final_order = sent_order + ['진짜불명확']\n",
        "df['선고유형_확장'] = df['선고유형_확장'].cat.set_categories(final_order, ordered=True)\n",
        "\n",
        "# --------------------------------------------------------사건 성격(형사/비형사/기타)\n",
        "\n",
        "RE_CRIMINAL = re.compile(r'(징역|금고|벌금형|벌금\\s*\\d|집행유예|무죄|약식명령|선고유예|보호관찰|사회봉사|수강명령)')\n",
        "RE_CIVILADM = re.compile(r'(원고|피고|피신청인|피상고인|대여금|보험|회생|분양|공제|상계|감정평가|소송비용|가처분|손해배상|부당이득)')\n",
        "df['사건_성격'] = np.where(\n",
        "    df['본문_정규화'].apply(lambda s: bool(RE_CRIMINAL.search(s) if isinstance(s,str) else False)),\n",
        "    '형사',\n",
        "    np.where(df['본문_정규화'].apply(lambda s: bool(RE_CIVILADM.search(s) if isinstance(s,str) else False)), '비형사', '기타')\n",
        ")\n",
        "\n",
        "\n",
        "#------------------------------------------------------법원명 지역/권역 파생\n",
        "\n",
        "df['법원명'] = df.get('법원명', pd.Series(index=df.index, dtype='object'))\n",
        "df['법원명'] = df['법원명'].astype(str).str.strip().replace({'': np.nan, 'nan': np.nan, 'None': np.nan})\n",
        "\n",
        "cand_cols = [c for c in ['사건명','본문_정규화','본문','판결요지','요지','결론'] if c in df.columns]\n",
        "\n",
        "def build_search_text(row):\n",
        "    parts = []\n",
        "    for c in cand_cols:\n",
        "        v = row.get(c)\n",
        "        if isinstance(v, str) and v.strip():\n",
        "            parts.append(v)\n",
        "    s = ' \\n '.join(parts)\n",
        "    \n",
        "    replacements = {\n",
        "        '법 원':'법원','지 방 법 원':'지방법원','고 등 법 원':'고등법원',\n",
        "        '가 정 법 원':'가정법원','행 정 법 원':'행정법원',\n",
        "        '회 생 법 원':'회생법원','군 사 법 원':'군사법원',\n",
        "    }\n",
        "    for a,b in replacements.items():\n",
        "        s = s.replace(a,b)\n",
        "    return s\n",
        "\n",
        "def spaced(word: str) -> str:\n",
        "    return r'\\s*'.join(list(word))\n",
        "\n",
        "P_JIBANG = spaced('지방법원')\n",
        "P_GODEUNG = spaced('고등법원')\n",
        "P_GAJUNG  = spaced('가정법원')\n",
        "P_HAENGJ  = spaced('행정법원')\n",
        "P_HOESAE  = spaced('회생법원')\n",
        "P_GUNSA   = spaced('군사법원')\n",
        "P_DAEBO   = spaced('대법원')\n",
        "P_BEOBWON = spaced('법원')\n",
        "\n",
        "\n",
        "REGEXES = [\n",
        "    # 특수/상급법원\n",
        "    re.compile(fr'(?:{P_DAEBO}|헌법재판소|특허{P_BEOBWON}|{P_HAENGJ}|{P_GAJUNG}|{P_HOESAE}|{P_GUNSA})'),\n",
        "    # 시 + 상급법원\n",
        "    re.compile(fr'(서울|부산|대구|인천|광주|대전|울산|세종)\\s*(?:{P_GODEUNG}|{P_GAJUNG}|{P_HAENGJ}|{P_HOESAE})'),\n",
        "    # 본원+지원\n",
        "    re.compile(fr'([가-힣]{{2,10}})\\s*{P_JIBANG}\\s*([가-힣]{{2,10}})\\s*지원'),\n",
        "    # 서울 지방법원\n",
        "    re.compile(fr'서울\\s*(?:중앙|동부|서부|남부|북부)\\s*{P_JIBANG}'),\n",
        "    # 지방법원 (단독)\n",
        "    re.compile(fr'([가-힣]{{2,10}})\\s*{P_JIBANG}'),\n",
        "    # 지원 (단독)\n",
        "    re.compile(r'([가-힣]{2,10})\\s*지원'),\n",
        "    # 축약형\n",
        "    re.compile(r'([가-힣]{2,10})\\s*지법'),\n",
        "    re.compile(r'([가-힣]{2,10})\\s*고법'),\n",
        "    # 일반 법원\n",
        "    re.compile(r'([가-힣]{2,10})\\s*법원'),\n",
        "]\n",
        "\n",
        "def extract_court_from_text(row):\n",
        "    s = build_search_text(row)\n",
        "    if not s:\n",
        "        return None\n",
        "    \n",
        "    for chunk in (s[:2000], s[-2000:]):\n",
        "        for rx in REGEXES:\n",
        "            m = rx.search(chunk)\n",
        "            if m:\n",
        "                g = re.sub(r'\\s+', '', m.group(0))\n",
        "                g = re.sub(r'([가-힣]{2,10})지법$', r'\\1지방법원', g)\n",
        "                g = re.sub(r'([가-힣]{2,10})고법$', r'\\1고등법원', g)\n",
        "                return g\n",
        "    \n",
        "    for rx in REGEXES:\n",
        "        m = rx.search(s)\n",
        "        if m:\n",
        "            g = re.sub(r'\\s+', '', m.group(0))\n",
        "            g = re.sub(r'([가-힣]{2,10})지법$', r'\\1지방법원', g)\n",
        "            g = re.sub(r'([가-힣]{2,10})고법$', r'\\1고등법원', g)\n",
        "            return g\n",
        "    return None\n",
        "\n",
        "mask_blank = df['법원명'].isna()\n",
        "if mask_blank.any():\n",
        "    df.loc[mask_blank, '법원명'] = df.loc[mask_blank].apply(extract_court_from_text, axis=1)\n",
        "\n",
        "print('[법원명 보강 v4] 1차 추출 후 결측:', int(df['법원명'].isna().sum()))\n",
        "\n",
        "KEYVAL_RX = re.compile(r'(?:법\\s*원|선고\\s*법\\s*원|선고\\s*기관|재판\\s*부|재판\\s*부\\s*명)\\s*[:：]\\s*([^\\n]+)')\n",
        "def pick_from_keyval(row):\n",
        "    s = build_search_text(row)\n",
        "    if not s: return None\n",
        "    m = KEYVAL_RX.search(s)\n",
        "    if not m: return None\n",
        "    val = m.group(1).strip()\n",
        "    \n",
        "    val = re.sub(r'[【\\[\\(].*?[】\\]\\)]', '', val)\n",
        "    val = re.sub(r'(제?\\d{1,3}(?:부|형사부|민사부|행정부)|단독|합의부)$', '', val)\n",
        "    \n",
        "    val = re.sub(r'\\s+', '', val)\n",
        "    val = re.sub(r'([가-힣]{2,10})지법$', r'\\1지방법원', val)\n",
        "    val = re.sub(r'([가-힣]{2,10})고법$', r'\\1고등법원', val)\n",
        "    return val or None\n",
        "\n",
        "mask_kv = df['법원명'].isna()\n",
        "if mask_kv.any():\n",
        "    df.loc[mask_kv, '법원명'] = df.loc[mask_kv].apply(pick_from_keyval, axis=1)\n",
        "\n",
        "print('[법원명 보강 v4] 키:값 파싱 후 결측:', int(df['법원명'].isna().sum()))\n",
        "\n",
        "HEADER_TAIL_RX = re.compile(r'[-–—]{2,}\\s*([^\\n]{2,30})')\n",
        "\n",
        "def pick_from_header_tail(row):\n",
        "    s = build_search_text(row)\n",
        "    if not s:\n",
        "        return None\n",
        "    head = s[:1500]\n",
        "    m = HEADER_TAIL_RX.search(head)\n",
        "    if not m:\n",
        "        return None\n",
        "    val = m.group(1)\n",
        "    \n",
        "    val = re.sub(r'[【\\[\\(].*?[】\\]\\)]', '', val)\n",
        "    val = re.sub(r'(제?\\d{1,3}(?:부|형사부|민사부|행정부)|단독|합의부)$', '', val)\n",
        "    val = re.sub(r'\\s+', '', val)\n",
        "    val = re.sub(r'([가-힣]{2,10})지법$', r'\\1지방법원', val)\n",
        "    val = re.sub(r'([가-힣]{2,10})고법$', r'\\1고등법원', val)\n",
        "    \n",
        "    if 2 <= len(val) <= 30:\n",
        "        return val\n",
        "    return None\n",
        "\n",
        "_mask_hdr_tail = df['법원명'].isna()\n",
        "if _mask_hdr_tail.any():\n",
        "    df.loc[_mask_hdr_tail, '법원명'] = df.loc[_mask_hdr_tail].apply(pick_from_header_tail, axis=1)\n",
        "\n",
        "\n",
        "def spaced_token(tok: str) -> str:\n",
        "    return r'\\s*'.join(list(tok))\n",
        "\n",
        "CITY_TOKENS = [\n",
        "    '서울','부산','대구','인천','광주','대전','울산','세종',\n",
        "    '수원','의정부','성남','안양','고양','용인','부천','남양주','안산','과천','평택','파주','하남','의왕','광명','시흥','김포',\n",
        "    '창원','마산','진주','김해','양산','거제','통영','포항','구미','경주','안동','김천','경산','영천','상주','밀양','사천','거창',\n",
        "    '전주','군산','익산','정읍','남원','목포','여수','순천','광양','나주','해남','강진',\n",
        "    '대전','세종','청주','충주','제천','천안','공주','아산','서산','논산','당진','보령','홍성','보은','옥천','영동',\n",
        "    '춘천','원주','강릉','동해','속초','삼척','태백','영월','정선','평창','홍천','철원','화천','양구','인제','고성','양양',\n",
        "    '제주','서귀포',\n",
        "    '중앙','동부','서부','남부','북부'\n",
        "]\n",
        "CITY_ALT = r'(?:' + '|'.join(spaced_token(c) for c in CITY_TOKENS) + r')'\n",
        "\n",
        "P_JB = spaced_token('지방법원')\n",
        "P_GB = spaced_token('고등법원')\n",
        "P_LAW = spaced_token('법원')\n",
        "P_SUP = r'(?:' + '|'.join(map(spaced_token, ['헌법재판소','특허법원','행정법원','가정법원','회생법원','군사법원','대법원'])) + r')'\n",
        "\n",
        "\n",
        "RX_METHOD_WORD = re.compile(r'방\\s*법\\s*원')\n",
        "\n",
        "RX_SET = [\n",
        "    # 지방법원 지원\n",
        "    re.compile(rf'({CITY_ALT})\\s*{P_JB}\\s*({CITY_ALT})\\s*지원'),\n",
        "    # 서울 분국 지방법원\n",
        "    re.compile(rf'(?:{spaced_token(\"서울\")})\\s*(?:{spaced_token(\"중앙\")}|{spaced_token(\"동부\")}|{spaced_token(\"서부\")}|{spaced_token(\"남부\")}|{spaced_token(\"북부\")})\\s*{P_JB}'),\n",
        "    # 지방법원 / 고등법원\n",
        "    re.compile(rf'({CITY_ALT})\\s*(?:{P_JB}|{P_GB})'),\n",
        "    # 특수/상급법원 \n",
        "    re.compile(rf'(?:({CITY_ALT})\\s*)?{P_SUP}'),\n",
        "    # 일반 법원\n",
        "    re.compile(rf'({CITY_ALT})\\s*{P_LAW}'),\n",
        "]\n",
        "\n",
        "def _norm_token(s: str) -> str:\n",
        "    n = re.sub(r'\\s+', '', s)\n",
        "    n = re.sub(r'([가-힣]{2,10})지법$', r'\\1지방법원', n)\n",
        "    n = re.sub(r'([가-힣]{2,10})고법$', r'\\1고등법원', n)\n",
        "    return n\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def extract_precise_candidates(row):\n",
        "    s = build_search_text(row)\n",
        "    if not s: return []\n",
        "    hits = []\n",
        "    for rx in RX_SET:\n",
        "        for m in rx.finditer(s):\n",
        "            raw = m.group(0)\n",
        "            \n",
        "            if RX_METHOD_WORD.search(raw):\n",
        "                continue\n",
        "            hits.append(_norm_token(raw))\n",
        "    \n",
        "    hits = [h for h in hits if 2 <= len(h) <= 30 and '방법원' not in h]\n",
        "    return hits\n",
        "\n",
        "def pick_best(hits):\n",
        "    if not hits: return None\n",
        "    def score(h):\n",
        "        if re.match(r'^[가-힣]{2,10}지방법원[가-힣]{2,10}지원$', h): return (5, len(h))\n",
        "        if re.match(r'^서울(?:중앙|동부|서부|남부|북부)지방법원$', h): return (4, len(h))\n",
        "        if re.match(r'^[가-힣]{2,10}(지방법원|고등법원)$', h):       return (3, len(h))\n",
        "        if any(h.endswith(s) for s in ['헌법재판소','특허법원','행정법원','가정법원','회생법원','군사법원','대법원']):\n",
        "            return (3, len(h))\n",
        "        if re.match(r'^[가-힣]{2,10}법원$', h):                      return (2, len(h))\n",
        "        return (1, len(h))\n",
        "    cnt = Counter(hits)\n",
        "    return sorted(cnt, key=lambda x: (score(x)[0], cnt[x], score(x)[1]), reverse=True)[0]\n",
        "\n",
        "mask_prec = df['법원명'].isna()\n",
        "if mask_prec.any():\n",
        "    cand = df.loc[mask_prec].apply(extract_precise_candidates, axis=1)\n",
        "    df.loc[mask_prec, '법원명'] = cand.apply(pick_best)\n",
        "\n",
        "print('[법원명 보강 v4] 2차(정밀) 스캔 후 결측:', int(df['법원명'].isna().sum()))\n",
        "\n",
        "\n",
        "_extra_cols = [c for c in ['선고법원','선고기관','법원부서','재판부','재판부명','제목','표제','본문헤더'] if c in df.columns]\n",
        "cand_cols = list(dict.fromkeys(cand_cols + _extra_cols)) \n",
        "\n",
        "# 후보 모두 수집 정규식\n",
        "RX_COURT_ANY = re.compile(\n",
        "    r'(?:'\n",
        "    r'[가-힣]{2,10}\\s*지방법원\\s*[가-힣]{2,10}\\s*지원|'   \n",
        "    r'[가-힣]{2,10}\\s*지방법원|'                       \n",
        "    r'[가-힣]{2,10}\\s*고등법원|'                       \n",
        "    r'(?:서울|부산|대구|대전|광주|수원)\\s*고등법원|'     \n",
        "    r'(?:헌법재판소|대법원|특허\\s*법원|행정\\s*법원|가정\\s*법원|회생\\s*법원|군사\\s*법원)|'\n",
        "    r'[가-힣]{2,10}\\s*지원|'                          \n",
        "    r'[가-힣]{2,10}\\s*법원'                           \n",
        "    r')'\n",
        ")\n",
        "\n",
        "def _normalize_court_token(s: str) -> str:\n",
        "    n = re.sub(r'\\s+', '', s)\n",
        "    n = re.sub(r'([가-힣]{2,10})지법$', r'\\1지방법원', n)\n",
        "    n = re.sub(r'([가-힣]{2,10})고법$', r'\\1고등법원', n)\n",
        "    n = n.replace('특허법원', '특허법원').replace('행정법원','행정법원').replace('가정법원','가정법원').replace('회생법원','회생법원').replace('군사법원','군사법원')\n",
        "    return n\n",
        "\n",
        "def extract_court_candidates_all(row) -> list:\n",
        "    s = build_search_text(row)\n",
        "    if not s: return []\n",
        "    hits = [_normalize_court_token(m.group(0)) for m in RX_COURT_ANY.finditer(s)]\n",
        "    # 너무 긴 것/짧은 것 컷(이상치 제거)\n",
        "    hits = [h for h in hits if 2 <= len(h) <= 30]\n",
        "    return hits\n",
        "\n",
        "def pick_best_court(hits: list) -> str|None:\n",
        "    if not hits: return None\n",
        "    # 선호도: (1) 지방법원+지원(복합) > (2) 지방법원/고등법원/특수법원 > (3) 단독 지원 > (4) 일반 법원\n",
        "    def score(h):\n",
        "        if re.match(r'^[가-힣]{2,10}지방법원[가-힣]{2,10}지원$', h): return (4, len(h))\n",
        "        if re.match(r'^[가-힣]{2,10}(지방법원|고등법원)$', h):         return (3, len(h))\n",
        "        if any(h.endswith(suf) for suf in ['헌법재판소','특허법원','행정법원','가정법원','회생법원','군사법원','대법원']): \n",
        "            return (3, len(h))\n",
        "        if re.match(r'^[가-힣]{2,10}지원$', h):                        return (2, len(h))\n",
        "        if re.match(r'^[가-힣]{2,10}법원$', h):                        return (1, len(h))\n",
        "        return (0, len(h))\n",
        "    # 빈도 우선 → 점수 → 길이\n",
        "    from collections import Counter\n",
        "    cnt = Counter(hits)\n",
        "    best = sorted(cnt.items(), key=lambda kv: (score(kv[0])[0], cnt[kv[0]], score(kv[0])[1]), reverse=True)[0][0]\n",
        "    return best\n",
        "\n",
        "mask_blank2 = df['법원명'].isna()\n",
        "if mask_blank2.any():\n",
        "    cand_series = df.loc[mask_blank2].apply(extract_court_candidates_all, axis=1)\n",
        "    picked = cand_series.apply(pick_best_court)\n",
        "    df.loc[mask_blank2, '법원명'] = picked\n",
        "    # 중간 점검\n",
        "    print('[법원명 보강 v4] 2차 스캔 후 결측:', int(df['법원명'].isna().sum()))\n",
        "\n",
        "mask_none = df['법원명'].isna()\n",
        "\n",
        "# 텍스트에서 '지방법원' 우선 복구\n",
        "RX_BASE_ONLY = re.compile(r'([가-힣]{2,10})\\s*지방법원')\n",
        "def _recover_base_only(row):\n",
        "    s = build_search_text(row)\n",
        "    if not isinstance(s, str): return None\n",
        "    m = RX_BASE_ONLY.search(s)\n",
        "    return re.sub(r'\\s+', '', m.group(0)) if m else None\n",
        "\n",
        "df.loc[mask_none, '법원명'] = df.loc[mask_none].apply(_recover_base_only, axis=1)\n",
        "\n",
        "# 그래도 None이면 '지원' 복구\n",
        "mask_none = df['법원명'].isna()\n",
        "RX_SUPPORT_ONLY = re.compile(r'([가-힣]{2,10})\\s*지원')\n",
        "def _recover_support_only(row):\n",
        "    s = build_search_text(row)\n",
        "    if not isinstance(s, str): return None\n",
        "    m = RX_SUPPORT_ONLY.search(s)\n",
        "    return re.sub(r'\\s+', '', m.group(0)) if m else None\n",
        "\n",
        "df.loc[mask_none, '법원명'] = df.loc[mask_none].apply(_recover_support_only, axis=1)\n",
        "\n",
        "print('[법원명 보강 v4] 복구 후 결측:', int(df['법원명'].isna().sum()))\n",
        "\n",
        "# 4) 시도/권역 파생\n",
        "\n",
        "SIDO_FULL = {\n",
        "    '서울':'서울특별시','인천':'인천광역시','부산':'부산광역시','대구':'대구광역시',\n",
        "    '광주':'광주광역시','대전':'대전광역시','울산':'울산광역시','세종':'세종특별자치시',\n",
        "    '경기':'경기도','강원':'강원특별자치도','충북':'충청북도','충남':'충청남도',\n",
        "    '전북':'전라북도','전남':'전라남도','경북':'경상북도','경남':'경상남도','제주':'제주특별자치도'\n",
        "}\n",
        "\n",
        "BASE_CITY_TO_SIDO = {\n",
        "    # 수도권\n",
        "    '서울':'서울','인천':'인천','수원':'경기','의정부':'경기','성남':'경기','안양':'경기','고양':'경기',\n",
        "    '용인':'경기','부천':'경기','남양주':'경기','안산':'경기','과천':'경기','평택':'경기','파주':'경기',\n",
        "    '하남':'경기','의왕':'경기','광명':'경기','시흥':'경기','김포':'경기',\n",
        "\n",
        "    # 서울 분국 토큰\n",
        "    '중앙':'서울','동부':'서울','서부':'서울','남부':'서울','북부':'서울',\n",
        "\n",
        "    # 영남\n",
        "    '부산':'부산','대구':'대구','울산':'울산',\n",
        "    '창원':'경남','마산':'경남','진주':'경남','김해':'경남','양산':'경남','거제':'경남','통영':'경남',\n",
        "    '포항':'경북','구미':'경북','경주':'경북','안동':'경북','김천':'경북','경산':'경북','영천':'경북','상주':'경북',\n",
        "    '밀양':'경남','사천':'경남','거창':'경남',\n",
        "\n",
        "    # 호남\n",
        "    '광주':'광주','전주':'전북','군산':'전북','익산':'전북','정읍':'전북','남원':'전북',\n",
        "    '목포':'전남','여수':'전남','순천':'전남','광양':'전남','나주':'전남','해남':'전남','강진':'전남',\n",
        "\n",
        "    # 충청\n",
        "    '대전':'대전','세종':'세종','청주':'충북','충주':'충북','제천':'충북',\n",
        "    '천안':'충남','공주':'충남','아산':'충남','서산':'충남','논산':'충남','당진':'충남','보령':'충남','홍성':'충남',\n",
        "    '보은':'충북','옥천':'충북','영동':'충북',\n",
        "\n",
        "    # 강원/제주\n",
        "    '춘천':'강원','원주':'강원','강릉':'강원','동해':'강원','속초':'강원','삼척':'강원','태백':'강원',\n",
        "    '영월':'강원','정선':'강원','평창':'강원','홍천':'강원','철원':'강원','화천':'강원',\n",
        "    '양구':'강원','인제':'강원','고성':'강원','양양':'강원',\n",
        "    '제주':'제주','서귀포':'제주',\n",
        "}\n",
        "\n",
        "SPECIAL_TO_SIDO = {\n",
        "    '특허법원':'대전',\n",
        "    '헌법재판소':'서울',\n",
        "    '행정법원':'서울',\n",
        "    '가정법원':'서울',\n",
        "    '회생법원':'서울',\n",
        "    '군사법원':'서울',\n",
        "    '대법원':'서울',\n",
        "}\n",
        "\n",
        "SIDO_DEFAULT_COURT = {\n",
        "    '서울특별시':'서울중앙지방법원',\n",
        "    '경기도':'수원지방법원',\n",
        "    '인천광역시':'인천지방법원',\n",
        "    '부산광역시':'부산지방법원',\n",
        "    '대구광역시':'대구지방법원',\n",
        "    '광주광역시':'광주지방법원',\n",
        "    '대전광역시':'대전지방법원',\n",
        "    '울산광역시':'울산지방법원',\n",
        "    '세종특별자치시':'대전지방법원',   \n",
        "    '강원특별자치도':'춘천지방법원',\n",
        "    '충청북도':'청주지방법원',\n",
        "    '충청남도':'대전지방법원',        \n",
        "    '전라북도':'전주지방법원',\n",
        "    '전라남도':'광주지방법원',\n",
        "    '경상북도':'대구지방법원',\n",
        "    '경상남도':'창원지방법원',\n",
        "    '제주특별자치도':'제주지방법원',\n",
        "}\n",
        "\n",
        "\n",
        "SEOUL_BRANCH = {'중앙','동부','서부','남부','북부'}\n",
        "\n",
        "def clean_false_court(n: str) -> str | None:\n",
        "    if not isinstance(n, str) or not n.strip():\n",
        "        return None\n",
        "    n = re.sub(r'\\s+', '', n)\n",
        "    n = re.sub(r'([가-힣]{2,10})지법$', r'\\1지방법원', n)\n",
        "    n = re.sub(r'([가-힣]{2,10})고법$', r'\\1고등법원', n)\n",
        "\n",
        "    # 특수/상급법원 통과\n",
        "    if any(n.endswith(s) or n == s for s in ['헌법재판소','대법원','특허법원','행정법원','가정법원','회생법원','군사법원']):\n",
        "        return n\n",
        "\n",
        "    # 서울 분국 형태 보존\n",
        "    if re.match(r'^서울(중앙|동부|서부|남부|북부)지방법원$', n): return n\n",
        "    if re.match(r'^(중앙|동부|서부|남부|북부)지방법원$', n): return n\n",
        "    if re.match(r'^(중앙|동부|서부|남부|북부)지원$', n): return n\n",
        "\n",
        "    # 복합형\n",
        "    m = re.match(r'^([가-힣]{2,10})지방법원([가-힣]{2,10})지원$', n)\n",
        "    if m:\n",
        "        b, br = m.group(1), m.group(2)\n",
        "        if b in BASE_CITY_TO_SIDO and (br in BASE_CITY_TO_SIDO or br in SEOUL_BRANCH):\n",
        "            return n\n",
        "        if b in BASE_CITY_TO_SIDO:\n",
        "            return f'{b}지방법원'\n",
        "        return n \n",
        "\n",
        "    # 단독 지방법원/고등법원\n",
        "    m = re.match(r'^([가-힣]{2,10})(지방법원|고등법원)$', n)\n",
        "    if m:\n",
        "        city = m.group(1)\n",
        "        if city in BASE_CITY_TO_SIDO: return n\n",
        "        if city.startswith('서울') and city.replace('서울','') in SEOUL_BRANCH: return n\n",
        "        if any(tok in n for tok in BASE_CITY_TO_SIDO): return n\n",
        "        return n\n",
        "\n",
        "    # '지원' 단독\n",
        "    m = re.match(r'^([가-힣]{2,10})지원$', n)\n",
        "    if m and (m.group(1) in BASE_CITY_TO_SIDO or m.group(1) in SEOUL_BRANCH):\n",
        "        return n\n",
        "\n",
        "    # 일반 '법원' — '방법원' 노이즈 제외, 도시/분국 토큰 있으면 보존\n",
        "    if n.endswith('법원') and '방법원' not in n:\n",
        "        if any(tok in n for tok in BASE_CITY_TO_SIDO) or any(b in n for b in SEOUL_BRANCH):\n",
        "            n = re.sub(r'(제?\\d{1,3}(?:부|형사부|민사부|행정부)|단독|합의부)$', '', n)\n",
        "            return n\n",
        "        return None\n",
        "\n",
        "    return n\n",
        "\n",
        "df['법원명'] = df['법원명'].apply(clean_false_court)\n",
        "print('[법원명 보강 v4] 보수버전 재클리닝 후 결측:', int(df['법원명'].isna().sum()))\n",
        "\n",
        "SEOUL_BRANCH = {'중앙','동부','서부','남부','북부'}\n",
        "\n",
        "def infer_sido_from_court(name: str) -> str:\n",
        "    if not isinstance(name, str) or not name.strip():\n",
        "        return '미상'\n",
        "    name = re.sub(r'\\s+', '', name)\n",
        "\n",
        "    # 0) '중앙/동부/서부/남부/북부 지방법원' (서울 없음)\n",
        "    if re.match(r'^(중앙|동부|서부|남부|북부)지방법원$', name):\n",
        "        return SIDO_FULL['서울']\n",
        "\n",
        "    # 복합형: 지방법원    지원\n",
        "    m = re.match(r'^([가-힣]{2,10})지방법원([가-힣]{2,10})지원$', name)\n",
        "    if m:\n",
        "        base, br = m.group(1), m.group(2)\n",
        "        city = br if br in BASE_CITY_TO_SIDO else base\n",
        "        return SIDO_FULL.get(BASE_CITY_TO_SIDO.get(city, ''), '미상')\n",
        "\n",
        "    # 단독형: 지방법원 / 고등법원\n",
        "    m = re.match(r'^([가-힣]{2,10})(지방법원|고등법원)$', name)\n",
        "    if m:\n",
        "        city = m.group(1)\n",
        "        if city in SEOUL_BRANCH:\n",
        "            return SIDO_FULL['서울']\n",
        "        return SIDO_FULL.get(BASE_CITY_TO_SIDO.get(city, ''), '미상')\n",
        "\n",
        "    # 단독형: 지원\n",
        "    m = re.match(r'^([가-힣]{2,10})지원$', name)\n",
        "    if m:\n",
        "        city = m.group(1)\n",
        "        if city in SEOUL_BRANCH:\n",
        "            return SIDO_FULL['서울']\n",
        "        return SIDO_FULL.get(BASE_CITY_TO_SIDO.get(city, ''), '미상')\n",
        "\n",
        "    # 특수/상급법원 (서울행정법원 등 접두 도시 반영)\n",
        "    for suf, base_city in SPECIAL_TO_SIDO.items():\n",
        "        if name.endswith(suf) or name == suf:\n",
        "            m2 = re.match(r'^([가-힣]{2,10})' + re.escape(suf) + r'$', name)\n",
        "            if m2 and m2.group(1) in BASE_CITY_TO_SIDO:\n",
        "                return SIDO_FULL[BASE_CITY_TO_SIDO[m2.group(1)]]\n",
        "            return SIDO_FULL[BASE_CITY_TO_SIDO.get(base_city, base_city)]\n",
        "\n",
        "    # 일반:   법원\n",
        "    m = re.match(r'^([가-힣]{2,10})법원', name)\n",
        "    if m:\n",
        "        tok = m.group(1)\n",
        "        if tok in BASE_CITY_TO_SIDO:\n",
        "            return SIDO_FULL[BASE_CITY_TO_SIDO[tok]]\n",
        "        if tok in SEOUL_BRANCH:\n",
        "            return SIDO_FULL['서울']\n",
        "\n",
        "    # 내부 토큰 스캔\n",
        "    for city, sido in BASE_CITY_TO_SIDO.items():\n",
        "        if city in name:\n",
        "            return SIDO_FULL[sido]\n",
        "    if any(b in name for b in SEOUL_BRANCH):\n",
        "        return SIDO_FULL['서울']\n",
        "\n",
        "    return '미상'\n",
        "\n",
        "df['시도'] = df['법원명'].apply(infer_sido_from_court)\n",
        "mask_fill = df['법원명'].isna() & df['시도'].ne('미상')\n",
        "df.loc[mask_fill, '법원명'] = df.loc[mask_fill, '시도'].map(SIDO_DEFAULT_COURT)\n",
        "print('[법원명 보강 v4] 시도기반 기본값 보강 후 결측:', int(df['법원명'].isna().sum()))\n",
        "\n",
        "# 2차 보정: 아직 '미상'이면 텍스트 전체에서 도시/분국 토큰을 재검색해 시도 추정\n",
        "mask_unk = df['시도'].eq('미상')\n",
        "\n",
        "def _guess_sido_from_text(row):\n",
        "    s = build_search_text(row)\n",
        "    if not isinstance(s, str): return None\n",
        "    s_nospace = re.sub(r'\\s+', '', s)\n",
        "    # 서울 분국 토큰\n",
        "    if any(b in s_nospace for b in SEOUL_BRANCH):\n",
        "        return SIDO_FULL['서울']\n",
        "    # 도시 토큰\n",
        "    for city, sido in BASE_CITY_TO_SIDO.items():\n",
        "        if city in s_nospace:\n",
        "            return SIDO_FULL[sido]\n",
        "    return None\n",
        "\n",
        "df.loc[mask_unk, '시도'] = df.loc[mask_unk].apply(_guess_sido_from_text, axis=1).fillna(df.loc[mask_unk, '시도'])\n",
        "\n",
        "# '미상'을 정말 0으로 만들기\n",
        "df['시도'] = df['시도'].replace('미상', SIDO_FULL['서울'])\n",
        "\n",
        "# (경고/점검 출력은 여기서!)\n",
        "if (df['시도'] == '미상').any():\n",
        "    print('[경고] 시도 미분류 건수:', int((df['시도']=='미상').sum()))\n",
        "    print(df.loc[df['시도']=='미상','법원명'].dropna().unique()[:20])\n",
        "\n",
        "\n",
        "SIDO2DO = {\n",
        "    '서울특별시':'서울','인천광역시':'인천','부산광역시':'부산','대구광역시':'대구','광주광역시':'광주',\n",
        "    '대전광역시':'대전','울산광역시':'울산','세종특별자치시':'세종','경기도':'경기','강원특별자치도':'강원',\n",
        "    '충청북도':'충북','충청남도':'충남','전라북도':'전북','전라남도':'전남','경상북도':'경북','경상남도':'경남','제주특별자치도':'제주'\n",
        "}\n",
        "REGION_MAP = {\n",
        "    '서울특별시':'수도권','인천광역시':'수도권','경기도':'수도권',\n",
        "    '부산광역시':'영남','대구광역시':'영남','울산광역시':'영남','경상북도':'영남','경상남도':'영남',\n",
        "    '광주광역시':'호남','전라북도':'호남','전라남도':'호남',\n",
        "    '대전광역시':'충청','세종특별자치시':'충청','충청북도':'충청','충청남도':'충청',\n",
        "    '강원특별자치도':'강원','제주특별자치도':'제주'\n",
        "}\n",
        "\n",
        "df['법원_도']   = df['시도'].map(SIDO2DO).fillna('미상')\n",
        "df['법원_권역'] = df['시도'].map(REGION_MAP).fillna('기타')\n",
        "df['법원_권역_세분'] = df['법원_권역']\n",
        "mask_fill2 = df['법원명'].isna() & df['시도'].ne('미상')\n",
        "df.loc[mask_fill2, '법원명'] = df.loc[mask_fill2, '시도'].map(SIDO_DEFAULT_COURT)\n",
        "print('[법원명 보강 v4] 시도기반 기본값 보강(2차) 후 결측:', int(df['법원명'].isna().sum()))\n",
        "\n",
        "COURT_OK_PAT = re.compile(r'(?:지방법원|고등법원|대법원|헌법재판소|특허법원|행정법원|가정법원|회생법원|군사법원)$')\n",
        "\n",
        "def _norm_blank_to_nan(x):\n",
        "    if not isinstance(x, str): return np.nan\n",
        "    x2 = x.strip()\n",
        "    return np.nan if x2 in ['', 'nan', 'None'] else x2\n",
        "\n",
        "df['법원명'] = df['법원명'].apply(_norm_blank_to_nan)\n",
        "\n",
        "# \"방 법 원\" 노이즈만 컷(지/고 '방 법 원' 예외 보존)\n",
        "mask_noise = df['법원명'].fillna('').str.contains(r'방\\s*법\\s*원', regex=True) & \\\n",
        "             ~df['법원명'].fillna('').str.contains(r'(?:지\\s*방\\s*법\\s*원|고\\s*등\\s*법\\s*원)', regex=True)\n",
        "df.loc[mask_noise, '법원명'] = np.nan\n",
        "\n",
        "# 축약형 보정\n",
        "def _expand_short(x):\n",
        "    if not isinstance(x, str): return x\n",
        "    x = re.sub(r'\\s+', '', x)\n",
        "    x = re.sub(r'([가-힣]{2,10})지법$', r'\\1지방법원', x)\n",
        "    x = re.sub(r'([가-힣]{2,10})고법$', r'\\1고등법원', x)\n",
        "    return x\n",
        "df['법원명'] = df['법원명'].apply(_expand_short)\n",
        "\n",
        "# 법원 패턴 아닌 값은 일단 NaN\n",
        "mask_not_court = df['법원명'].notna() & ~df['법원명'].str.contains(COURT_OK_PAT)\n",
        "df.loc[mask_not_court, '법원명'] = np.nan\n",
        "\n",
        "# 시도 기반 1차 채움\n",
        "mask_fill = df['법원명'].isna() & df['시도'].notna() & (df['시도'] != '미상')\n",
        "df.loc[mask_fill, '법원명'] = df.loc[mask_fill, '시도'].map(SIDO_DEFAULT_COURT)\n",
        "\n",
        "# 정책적으로 허용 시, 남은 값은 서울중앙으로 채움(원치 않으면 이 줄만 주석)\n",
        "df['법원명'] = df['법원명'].fillna('서울중앙지방법원')\n",
        "\n",
        "# 최종 점검\n",
        "print('[법원명 패치] 최종 결측:', int(df['법원명'].isna().sum()))\n",
        "\n",
        "\n",
        "# 기타 권역 점검 출력\n",
        "etc_rows = df.loc[df['법원_권역']=='기타', ['법원명','시도','법원_도','법원_권역']].dropna(subset=['법원명']).drop_duplicates().sort_values(['시도','법원명'])\n",
        "print(f\"[참고] 기타 권역 행 수: {len(etc_rows)}\")\n",
        "if len(etc_rows):\n",
        "    print(\"기타 권역 법원명 리스트 (시도 함께):\")\n",
        "    for _, r in etc_rows.iterrows():\n",
        "        print(f\"- {r['법원명']}  | 시도={r['시도']}  | 도={r['법원_도']}\")\n",
        "else:\n",
        "    print(\"기타 권역 없음(또는 모두 분류됨).\")\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------------------------------선고일/심급/상소/감형\n",
        "\n",
        "df['선고일'] = pd.to_datetime(df.get('선고일') if '선고일' in df.columns else df.get('선고일자'), errors='coerce')\n",
        "df['선고연도'] = df['선고일'].dt.year\n",
        "df['선고분기'] = df['선고일'].dt.quarter\n",
        "df = df.sort_values(['선고일','법원_권역']).reset_index(drop=True)\n",
        "\n",
        "def law_list(name):\n",
        "    if pd.isna(name): return None\n",
        "    if '지방법원' in name: return '1심'\n",
        "    if '고등법원' in name: return '2심'\n",
        "    if '대법원' in name: return '3심'\n",
        "    return '기타'\n",
        "df['심급_from_법원명'] = df['법원명'].apply(law_list)\n",
        "\n",
        "심급_from_txt = np.select(\n",
        "    [txt.str.contains(r'대법원|상고', na=False), txt.str.contains(r'항소|원심|항소심|항고', na=False)],\n",
        "    ['3심', '2심'], default=None\n",
        ")\n",
        "df['심급'] = np.where(pd.notna(심급_from_txt), 심급_from_txt,\n",
        "               np.where(pd.notna(df['심급_from_법원명']), df['심급_from_법원명'], '1심'))\n",
        "df['상소여부'] = df['심급'] != '1심'\n",
        "\n",
        "after_jumun = df['본문_정규화'].str.split(' 주문 ', n=1).apply(lambda x: x[1] if isinstance(x, list) and len(x)>1 else None)\n",
        "tail = df['본문_정규화'].str[-800:]\n",
        "def pick_result(row):\n",
        "    for z in [row['after'], row['tail']]:\n",
        "        if not isinstance(z, str): continue\n",
        "        if re.search(r'(상고|항소|항고|청구).*(기각)', z): return '기각'\n",
        "        if re.search(r'(상고|항소|항고|청구).*(인용)', z): return '인용'\n",
        "        if re.search(r'원심판결을\\s*파기', z):          return '파기'\n",
        "        if re.search(r'파기환송|환송', z):              return '파기환송'\n",
        "        if re.search(r'원심(?:을)?\\s*유지', z):         return '기각'\n",
        "    return None\n",
        "tmp = pd.DataFrame({'after': after_jumun, 'tail': tail})\n",
        "res = tmp.apply(pick_result, axis=1)\n",
        "df['상소결과_보강'] = res.combine_first(df.get('상소결과', pd.Series(index=df.index, dtype='object')))\n",
        "\n",
        "df['감형키워드'] = pd.Series(df.get('감형키워드', False), index=df.index).fillna(False).astype(bool)\n",
        "src_outcome = (\n",
        "    df.get('상소결과_보강', pd.Series(index=df.index, dtype='object'))\n",
        "      .combine_first(df.get('상소결과', pd.Series(index=df.index, dtype='object')))\n",
        "      .fillna('')\n",
        ")\n",
        "df['감형사건_광의'] = src_outcome.isin(['인용','파기환송']).astype(bool) | df['감형키워드']\n",
        "df['감형사건_보수'] = (src_outcome.isin(['파기환송']) | txt.str.contains(r'감형|감경', na=False)).astype(bool)\n",
        "\n",
        "# ---------------------------------------------------------------후처리 안전 보정\n",
        "\n",
        "df['판사명'] = df['판사명'].fillna('판사미상')\n",
        "df['판사_권역수'] = df.groupby('판사명')['법원_권역'].transform('nunique').fillna(0).astype(int)\n",
        "df['판사_이동여부'] = df['판사_권역수'] > 1\n",
        "\n",
        "\n",
        "src = (sget('상소결과_보강').combine_first(sget('상소결과')).fillna('')).astype(str)\n",
        "def to_major_outcome(x: str):\n",
        "    if not isinstance(x, str): return '기타'\n",
        "    if re.search(r'파기환송|환송', x): return '파기/환송'\n",
        "    if '파기' in x: return '파기/환송'\n",
        "    if '인용' in x: return '인용'\n",
        "    if '기각' in x: return '기각'\n",
        "    return '기타'\n",
        "df['상소결과_대분류'] = src.apply(to_major_outcome)\n",
        "df['상소결과_최종'] = df.get('상소결과_보강').where(df.get('상소결과_보강').notna(), df.get('상소결과'))\n",
        "df['사건_성격'] = df['사건_성격'].fillna('기타').astype(str)\n",
        "df['선고유형_확장'] = df['선고유형_확장'].astype(str)\n",
        "\n",
        "# 선고유형_대분류 보장(없을 때만 생성)\n",
        "if '선고유형_대분류' not in df.columns:\n",
        "    def to_major_sentence(row):\n",
        "        v = str(row.get('선고유형_확장','') or row.get('선고유형','')).strip()\n",
        "        if v in ['실형','집행유예','벌금','무죄','약식','선고유예','보호처분','공소기각/각하']:\n",
        "            return v if v in ['실형','집행유예','벌금','무죄'] else '기타'\n",
        "        if bool(row.get('실형확인여부', False)): return '실형'\n",
        "        if bool(row.get('집행유예_여부', False)): return '집행유예'\n",
        "        if bool(row.get('벌금형확인여부', False)): return '벌금'\n",
        "        if str(row.get('형종','')) == '무죄': return '무죄'\n",
        "        return '기타'\n",
        "    df['선고유형_대분류'] = df.apply(to_major_sentence, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------------------세팅하기 (최종확인)\n",
        "\n",
        "def ensure_list(v):\n",
        "    if isinstance(v, list): return v\n",
        "    if pd.isna(v) or v is None: return []\n",
        "    return [v]\n",
        "\n",
        "df['범죄키워드_리스트'] = df['범죄키워드_리스트'].apply(ensure_list)\n",
        "\n",
        "kw_df = df.explode('범죄키워드_리스트')\n",
        "kw_df = kw_df[kw_df['범죄키워드_리스트'].astype(str).str.strip().ne('')]\n",
        "\n",
        "\n",
        "if {'사건번호','법원_권역','범죄키워드_리스트'}.issubset(kw_df.columns):\n",
        "    kw_df = kw_df.drop_duplicates(['사건번호','법원_권역','범죄키워드_리스트'])\n",
        "\n",
        "print('Done!!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결측 제거 후 유형 분포 확인\n",
        "\n",
        "assert df['법원명'].isna().sum() == 0, \"법원명 결측이 다시 생겼습니다.\"\n",
        "assert (df['시도'] != '미상').all(), \"시도에 '미상'이 남아있습니다.\"\n",
        "\n",
        "\n",
        "COURT_OK_PAT = re.compile(r'(?:지방법원|고등법원|대법원|헌법재판소|특허법원|행정법원|가정법원|회생법원|군사법원)$')\n",
        "mask_bad = ~(\n",
        "    df['법원명'].str.contains(COURT_OK_PAT) |\n",
        "    df['법원명'].str.endswith('지원')\n",
        ")\n",
        "if mask_bad.any():\n",
        "    print(\"[점검] 비표준 법원명 상위 20개\")\n",
        "    print(df.loc[mask_bad,'법원명'].value_counts().head(20))\n",
        "\n",
        "SIDO_DOMAIN = {\n",
        "    '서울특별시','인천광역시','부산광역시','대구광역시','광주광역시','대전광역시','울산광역시','세종특별자치시',\n",
        "    '경기도','강원특별자치도','충청북도','충청남도','전라북도','전라남도','경상북도','경상남도','제주특별자치도'\n",
        "}\n",
        "REGION_DOMAIN = {'수도권','영남','호남','충청','강원','제주'}\n",
        "bad_sido = df.loc[~df['시도'].isin(SIDO_DOMAIN), '시도'].unique()\n",
        "bad_region = df.loc[~df['법원_권역'].isin(REGION_DOMAIN), '법원_권역'].unique()\n",
        "if len(bad_sido):   print(\"[점검] 시도 도메인 밖:\", bad_sido[:10])\n",
        "if len(bad_region): print(\"[점검] 권역 도메인 밖:\", bad_region[:10])\n",
        "\n",
        "\n",
        "print(\"법원명 유형 분포:\")\n",
        "print(df['법원명'].str.extract(r'(.*?)(지방법원|고등법원|대법원|헌법재판소|특허법원|행정법원|가정법원|회생법원|군사법원|지원)$')[1]\n",
        "        .fillna('기타').value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 지역별 범죄 키워드 Top1,2 나타내기\n",
        "\n",
        "# 권역 기준\n",
        "kw_piv_region = pd.pivot_table(\n",
        "    tmp_kw, index='법원_권역', columns='키워드',\n",
        "    aggfunc='size', fill_value=0  \n",
        ").sort_index()\n",
        "\n",
        "top12_region = (\n",
        "    kw_piv_region\n",
        "      .apply(lambda row: row[row > 0].nlargest(2), axis=1)  \n",
        "      .stack()\n",
        "      .reset_index(name='건수')\n",
        "      .rename(columns={'level_1':'키워드'})\n",
        "      .sort_values(['법원_권역','건수'], ascending=[True, False])\n",
        ")\n",
        "top12_region['rank'] = top12_region.groupby('법원_권역').cumcount() + 1\n",
        "top12_region['표기'] = top12_region['키워드'] + ' (' + top12_region['건수'].astype(int).astype(str) + ')'\n",
        "\n",
        "지역별_Top12 = (\n",
        "    top12_region.pivot(index='법원_권역', columns='rank', values='표기')\n",
        "                .rename(columns={1:'Top1', 2:'Top2'})\n",
        "                .reset_index()\n",
        ")\n",
        "\n",
        "print(\"▶ 권역 기준 Top1·Top2\")\n",
        "print(지역별_Top12)\n",
        "\n",
        "# 시도 기준\n",
        "kw_piv_sido = pd.pivot_table(\n",
        "    tmp_kw_sido, index='시도', columns='키워드',\n",
        "    aggfunc='size', fill_value=0\n",
        ").sort_index()\n",
        "\n",
        "top12_sido = (\n",
        "    kw_piv_sido\n",
        "      .apply(lambda row: row[row > 0].nlargest(2), axis=1)\n",
        "      .stack()\n",
        "      .reset_index(name='건수')\n",
        "      .rename(columns={'level_1':'키워드'})\n",
        "      .sort_values(['시도','건수'], ascending=[True, False])\n",
        ")\n",
        "top12_sido['rank'] = top12_sido.groupby('시도').cumcount() + 1\n",
        "top12_sido['표기'] = top12_sido['키워드'] + ' (' + top12_sido['건수'].astype(int).astype(str) + ')'\n",
        "\n",
        "시도별_Top12 = (\n",
        "    top12_sido.pivot(index='시도', columns='rank', values='표기')\n",
        "              .rename(columns={1:'Top1', 2:'Top2'})\n",
        "              .reset_index()\n",
        ")\n",
        "\n",
        "print(\"\\n▶ 시도 기준 Top1·Top2\")\n",
        "print(시도별_Top12)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from importlib.util import find_spec\n",
        "\n",
        "save_dir = r\"C:\\Users\\zkdlt\\Desktop\\SK_ASAC\\project\\good\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "base_name = \"권역 & 시도 범죄키워드 1위 2위\"\n",
        "xlsx_path = os.path.join(save_dir, f\"{base_name}.xlsx\")\n",
        "\n",
        "# NaN → 빈칸\n",
        "def _fill(df):\n",
        "    return df.fillna('') if isinstance(df, pd.DataFrame) else df\n",
        "\n",
        "지역별_Top12 = _fill(지역별_Top12)\n",
        "시도별_Top12 = _fill(시도별_Top12)\n",
        "Top12_long = _fill(Top12_long) if 'Top12_long' in globals() else None  # 있으면 함께 저장\n",
        "\n",
        "# 사용할 엑셀 엔진 선택\n",
        "engine = 'openpyxl' if find_spec('openpyxl') else ('xlsxwriter' if find_spec('xlsxwriter') else None)\n",
        "\n",
        "if engine:\n",
        "    with pd.ExcelWriter(xlsx_path, engine=engine) as xw:\n",
        "        지역별_Top12.to_excel(xw, sheet_name='권역 Top1-2', index=False)\n",
        "        시도별_Top12.to_excel(xw, sheet_name='시도 Top1-2', index=False)\n",
        "        if Top12_long is not None:\n",
        "            Top12_long.to_excel(xw, sheet_name='Top12_long', index=False)\n",
        "    print(\"엑셀 저장 완료 →\", xlsx_path)\n",
        "else:\n",
        "    # 엑셀 엔진이 없으면 CSV 세 장으로 저장\n",
        "    path1 = os.path.join(save_dir, \"권역 Top1-2.csv\")\n",
        "    path2 = os.path.join(save_dir, \"시도 Top1-2.csv\")\n",
        "    지역별_Top12.to_csv(path1, index=False, encoding='utf-8-sig')\n",
        "    시도별_Top12.to_csv(path2, index=False, encoding='utf-8-sig')\n",
        "    if Top12_long is not None:\n",
        "        path3 = os.path.join(save_dir, \"Top12_long.csv\")\n",
        "        Top12_long.to_csv(path3, index=False, encoding='utf-8-sig')\n",
        "    print(\"Excel 엔진이 없어 CSV로 저장했습니다. 폴더 →\", save_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. 1) 판사 성향 지역도 편차 확인(관용, 중립, 엄벌)\n",
        "# 지역에 따라 성향이 이렇게 다르다를 표현\n",
        "# 어느지역이 성향이 원만한가??\n",
        "\n",
        "df['심급'] = df['심급'].fillna('1심').astype(str)\n",
        "df['법원_권역'] = df['법원_권역'].fillna('기타')\n",
        "df['시도'] = df['시도'].fillna('미상')\n",
        "\n",
        "\n",
        "if '판사성향_버킷' not in df.columns:\n",
        "    base = df.groupby('판사명', observed=False)['형량_월_기준'].mean().rename('판사_평균형량')\n",
        "    q1, q2 = base.quantile([0.33, 0.66])\n",
        "    def _bucket(v):\n",
        "        if v <= q1:  return '관용'\n",
        "        if v >= q2:  return '엄벌'\n",
        "        return '중립'\n",
        "    bucket = base.apply(_bucket).rename('판사성향_버킷')\n",
        "    df = df.merge(bucket, left_on='판사명', right_index=True, how='left')\n",
        "\n",
        "# --- 피벗 생성 함수: 권역/시도 공용 ---\n",
        "cats = ['관용','중립','엄벌']\n",
        "\n",
        "def make_pivot(df_src, idx_cols):\n",
        "    # 관심 행만\n",
        "    df_use = df_src[df_src['판사성향_버킷'].isin(cats)].copy()\n",
        "    df_use['판사성향_버킷'] = pd.Categorical(df_use['판사성향_버킷'], categories=cats, ordered=True)\n",
        "\n",
        "    # 건수 피벗 (심급 + 지리축 × 성향버킷)\n",
        "    cnt = (pd.pivot_table(\n",
        "                df_use,\n",
        "                index=['심급'] + idx_cols,\n",
        "                columns='판사성향_버킷',\n",
        "                aggfunc='size',           \n",
        "                fill_value=0,\n",
        "                observed=False\n",
        "          ).reset_index())\n",
        "\n",
        "    # 모든 버킷 컬럼 보장 + 정렬\n",
        "    for c in cats:\n",
        "        if c not in cnt.columns:\n",
        "            cnt[c] = 0\n",
        "    cnt = cnt[['심급'] + idx_cols + cats]\n",
        "\n",
        "    # 점유율 & 편차\n",
        "    cnt['총건수'] = cnt[cats].sum(axis=1)\n",
        "    share = cnt[cats].div(cnt['총건수'].replace(0, np.nan), axis=0).fillna(0)\n",
        "    share.columns = [f'점유율_{c}' for c in cats]\n",
        "\n",
        "    # 컬럼명 정리(건수 접두사)\n",
        "    cnt.columns = ['심급'] + idx_cols + [f'건수_{c}' for c in cats] + ['총건수']\n",
        "\n",
        "    out = pd.concat([cnt, share], axis=1)\n",
        "    out['편차_엄벌-관용'] = out['점유율_엄벌'] - out['점유율_관용']\n",
        "    out['편차_중립대칭'] = (out['점유율_엄벌'] - out['점유율_관용']) / 2\n",
        "    return out\n",
        "\n",
        "# --- 권역/시도 피벗 ---\n",
        "권역_피벗 = make_pivot(df, ['법원_권역'])\n",
        "시도_피벗 = make_pivot(df, ['시도'])\n",
        "\n",
        "# -------------------------------------------------------테블로 저장\n",
        "save_dir = r\"C:\\Users\\zkdlt\\Desktop\\SK_ASAC\\project\\good\"\n",
        "save_path = save_dir + r\"\\판사성향에따른 지역편차.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(save_path, engine='openpyxl') as xw:\n",
        "    권역_피벗.to_excel(xw, sheet_name='권역_피벗', index=False)\n",
        "    시도_피벗.to_excel(xw, sheet_name='시도_피벗', index=False)\n",
        "    # 심급별 시트도 추가(필터 없이 바로 비교)\n",
        "    for lv in ['1심','2심','3심']:\n",
        "        권역_피벗.query(\"심급 == @lv\").to_excel(xw, sheet_name=f'권역_피벗_{lv}', index=False)\n",
        "        시도_피벗.query(\"심급 == @lv\").to_excel(xw, sheet_name=f'시도_피벗_{lv}', index=False)\n",
        "\n",
        "print(\"저장 완료 →\", save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) 지역도 관용, 중립, 엄벌 에 해당하는 범죄키워드 종류가 무엇인지? (결측치 제거)\n",
        "# 해당 판사 성향에서 잡는 사건의 범죄유형 조성이 이렇게 다르다!! \n",
        "# 성향 안에서 어떤 범죄키워드가 얼마나 차지하는지 보려고 함\n",
        "\n",
        "\n",
        "\n",
        "df['범죄키워드_리스트'] = df['범죄키워드_리스트'].apply(\n",
        "    lambda v: v if isinstance(v, list) else ([] if pd.isna(v) else [v])\n",
        ")\n",
        "kw_df = (df\n",
        "         .explode('범죄키워드_리스트')\n",
        "         .rename(columns={'범죄키워드_리스트':'키워드'}))\n",
        "kw_df = kw_df[kw_df['키워드'].astype(str).str.strip().ne('')]\n",
        "kw_df = kw_df[~kw_df['키워드'].astype(str).str.lower().isin({'nan','none','null'})]\n",
        "\n",
        "# 결측 기본값 + 성향 필터\n",
        "kw_df['심급'] = kw_df['심급'].fillna('1심').astype(str)\n",
        "kw_df['법원_권역'] = kw_df['법원_권역'].fillna('기타').astype(str)\n",
        "kw_df['시도'] = kw_df['시도'].fillna('미상').astype(str)\n",
        "cats = ['관용','중립','엄벌']\n",
        "kw_df = kw_df[kw_df['판사성향_버킷'].isin(cats)].copy()\n",
        "kw_df['판사성향_버킷'] = pd.Categorical(kw_df['판사성향_버킷'], categories=cats, ordered=True)\n",
        "\n",
        "# 열 고정용: 전체 키워드 빈도순\n",
        "all_kw = (kw_df.groupby('키워드', observed=True)\n",
        "                .size().sort_values(ascending=False).index.tolist())\n",
        "\n",
        "def wide_by(region_col):\n",
        "    # (심급, 지역, 성향, 키워드) → 건수\n",
        "    g = (kw_df.groupby(['심급', region_col, '판사성향_버킷', '키워드'], observed=True)\n",
        "                .size().rename('건수').reset_index())\n",
        "    # 건수 와이드\n",
        "    cnt = (g.pivot_table(index=['심급', region_col, '판사성향_버킷'],\n",
        "                         columns='키워드', values='건수', fill_value=0)\n",
        "             .reindex(columns=all_kw, fill_value=0)\n",
        "             .reset_index())\n",
        "    # 비율 와이드\n",
        "    kw_cols = [c for c in cnt.columns if c not in ['심급', region_col, '판사성향_버킷']]\n",
        "    share = cnt.copy()\n",
        "    row_sum = share[kw_cols].sum(axis=1).replace(0, np.nan)\n",
        "    share[kw_cols] = share[kw_cols].div(row_sum, axis=0).fillna(0)\n",
        "    share = share.rename(columns={c: f'{c}_비율' for c in kw_cols})\n",
        "    return cnt, share\n",
        "\n",
        "\n",
        "권역_건수, 권역_비율 = wide_by('법원_권역')\n",
        "시도_건수, 시도_비율 = wide_by('시도')\n",
        "\n",
        "\n",
        "out = r\"C:\\Users\\zkdlt\\Desktop\\SK_ASAC\\project\\good\\판사성향에 따른지역별 범죄키워드.xlsx\"\n",
        "with pd.ExcelWriter(out, engine='openpyxl') as xw:\n",
        "    권역_건수.to_excel(xw, sheet_name='권역_건수', index=False)\n",
        "    권역_비율.to_excel(xw, sheet_name='권역_비율', index=False)\n",
        "    시도_건수.to_excel(xw, sheet_name='시도_건수', index=False)\n",
        "    시도_비율.to_excel(xw, sheet_name='시도_비율', index=False)\n",
        "print(\"저장:\", out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. 판사에 따라 지역에서 1심,2심,3심 동일조건범죄 항소 및 감형 편차 확인 \n",
        "\n",
        "\n",
        "df['심급'] = df['심급'].fillna('1심').astype(str)\n",
        "df['법원_권역'] = df['법원_권역'].fillna('기타')\n",
        "df['시도'] = df['시도'].fillna('미상')\n",
        "for c in ['초범여부','재범여부','집행유예_여부','감형사건_광의','감형사건_보수']:\n",
        "    if c not in df.columns: df[c] = False\n",
        "    df[c] = df[c].fillna(False).astype(bool)\n",
        "\n",
        "# 상소결과 대분류(없으면 생성)\n",
        "if '상소결과_대분류' not in df.columns:\n",
        "    src = (df.get('상소결과_보강', pd.Series(index=df.index, dtype='object'))\n",
        "             .combine_first(df.get('상소결과', pd.Series(index=df.index, dtype='object')))\n",
        "             .fillna('').astype(str))\n",
        "    def _to_major_outcome(x: str):\n",
        "        if any(k in x for k in ['파기환송','환송','파기']): return '파기/환송'\n",
        "        if '인용' in x: return '인용'\n",
        "        if '기각' in x: return '기각'\n",
        "        return '기타'\n",
        "    df['상소결과_대분류'] = src.apply(_to_major_outcome)\n",
        "\n",
        "# 주요키워드(동일조건의 '범죄' 축): 리스트면 첫 유효항목, 없으면 '기타'\n",
        "def first_kw(v):\n",
        "    if isinstance(v, list):\n",
        "        for x in v:\n",
        "            if isinstance(x, str) and x.strip():\n",
        "                return x\n",
        "        return '기타'\n",
        "    return v if (isinstance(v, str) and v.strip()) else '기타'\n",
        "df['주요키워드'] = df.get('범죄키워드_리스트', []).apply(first_kw).astype(str)\n",
        "\n",
        "# 동일조건키(태블로에서 보기 편한 식별자)\n",
        "df['동일조건키'] = (\n",
        "    '범죄=' + df['주요키워드'] +\n",
        "    '|초범=' + df['초범여부'].astype(int).astype(str) +\n",
        "    '|재범=' + df['재범여부'].astype(int).astype(str) +\n",
        "    '|집유=' + df['집행유예_여부'].astype(int).astype(str)\n",
        ")\n",
        "\n",
        "# 비교 지표용 더미\n",
        "df['is_인용'] = (df['상소결과_대분류'] == '인용').astype(int)\n",
        "df['is_파환'] = (df['상소결과_대분류'] == '파기/환송').astype(int)\n",
        "df['is_기각'] = (df['상소결과_대분류'] == '기각').astype(int)\n",
        "df['형량_월_기준'] = pd.to_numeric(df.get('형량_월_기준', 0), errors='coerce').fillna(0)\n",
        "\n",
        "# 판사명 미상/생략/결측 행 과감히 제거 (익명 '○' 표기는 포함)\n",
        "df = df.copy()\n",
        "df['판사명'] = df['판사명'].astype(str).str.strip()  # ← .str.strip() 로!\n",
        "\n",
        "bad_vals = {'', '판사미상', '결에는', '단독', '생략', }\n",
        "mask_bad = (\n",
        "    df['판사명'].isin(bad_vals)\n",
        "    | df['판사명'].str.lower().isin({'nan', 'none'})\n",
        "    | df['판사명'].str.contains(r'(성명\\s*생략|기재\\s*생략|미상)$', na=False)\n",
        ")\n",
        "df = df.loc[~mask_bad].reset_index(drop=True)\n",
        "\n",
        "\n",
        "MIN_N = 5     # 각 심급별 최소 표본 수\n",
        "TOL   = 1e-9  # 부동소수 오차 허용\n",
        "\n",
        "\n",
        "def build_judge_region_diffs(region_col: str):\n",
        "    # 심급별 지표(판사×지역×동일조건×심급)\n",
        "    idx = ['판사명', region_col, '주요키워드', '초범여부', '재범여부', '집행유예_여부', '동일조건키', '심급']\n",
        "    g = (df.groupby(idx, dropna=False)\n",
        "           .agg(\n",
        "               건수=('심급','size'),\n",
        "               평균형량=('형량_월_기준','mean'),\n",
        "               감형률_광의=('감형사건_광의','mean'),\n",
        "               감형률_보수=('감형사건_보수','mean'),\n",
        "               비중_인용=('is_인용','mean'),\n",
        "               비중_파기환송=('is_파환','mean'),\n",
        "               비중_기각=('is_기각','mean')\n",
        "           )\n",
        "           .reset_index())\n",
        "    # 최소 표본 충족\n",
        "    g = g[g['건수'] >= MIN_N].copy()\n",
        "\n",
        "    # 심급별 프레임 준비(열 이름에 @심급)\n",
        "    base_cols = ['판사명', region_col, '주요키워드','초범여부','재범여부','집행유예_여부','동일조건키']\n",
        "    met_cols  = ['건수','평균형량','감형률_광의','감형률_보수','비중_인용','비중_파기환송','비중_기각']\n",
        "\n",
        "    def take(level):\n",
        "        sub = g[g['심급'] == level].copy()\n",
        "        sub = sub[base_cols + met_cols]\n",
        "        sub = sub.rename(columns={c: f'{c}@{level}' for c in met_cols})\n",
        "        return sub.set_index(base_cols)\n",
        "\n",
        "    L1, L2, L3 = take('1심'), take('2심'), take('3심')\n",
        "\n",
        "    # 심급쌍별 병합 + Δ계산 + 차이 있는 행만 보존\n",
        "    pairs = [('1심','2심'), ('2심','3심'), ('1심','3심')]\n",
        "    out_list = []\n",
        "\n",
        "    for a, b in pairs:\n",
        "        A = {'1심': L1, '2심': L2, '3심': L3}[a]\n",
        "        B = {'1심': L1, '2심': L2, '3심': L3}[b]\n",
        "        pair = A.join(B, how='inner')  # 두 심급 모두 표본 충족\n",
        "\n",
        "        # 양쪽 건수 하한 체크(병합 후도 안전하게)\n",
        "        pair = pair[(pair[f'건수@{a}'] >= MIN_N) & (pair[f'건수@{b}'] >= MIN_N)].copy()\n",
        "        if pair.empty: \n",
        "            continue\n",
        "\n",
        "        # Δ( b - a )\n",
        "        for m in ['평균형량','감형률_광의','감형률_보수','비중_인용','비중_파기환송','비중_기각']:\n",
        "            pair[f'Δ{m}({b}-{a})'] = pair[f'{m}@{b}'] - pair[f'{m}@{a}']\n",
        "\n",
        "        # “차이 없음” 제거 (모든 Δ가 거의 0이면 제거)\n",
        "        delta_cols = [c for c in pair.columns if c.startswith('Δ')]\n",
        "        keep = (pair[delta_cols].abs().max(axis=1) > TOL)\n",
        "        pair = pair[keep]\n",
        "        if pair.empty:\n",
        "            continue\n",
        "\n",
        "        pair = pair.reset_index()\n",
        "        pair.insert(0, '비교', f'{a}_vs_{b}')\n",
        "        out_list.append(pair)\n",
        "\n",
        "    if not out_list:\n",
        "        return pd.DataFrame(), g  # 차이 행이 없을 수도 있음\n",
        "\n",
        "    diffs = pd.concat(out_list, ignore_index=True)\n",
        "    # 정렬: 판사/지역/비교/범죄 순\n",
        "    diffs = diffs.sort_values(['판사명', region_col, '비교', '주요키워드', '초범여부','재범여부','집행유예_여부'])\n",
        "\n",
        "    # 태블로 가독성: bool → 문자열\n",
        "    for c in ['초범여부','재범여부','집행유예_여부']:\n",
        "        for fr in (diffs, g):\n",
        "            if c in fr.columns:\n",
        "                fr[c] = fr[c].map({True:'Y', False:'N'})\n",
        "\n",
        "    return diffs, g  # g는 심급별 원지표(참고용)\n",
        "\n",
        "\n",
        "\n",
        "권역_편차, 권역_심급지표 = build_judge_region_diffs('법원_권역')\n",
        "시도_편차, 시도_심급지표 = build_judge_region_diffs('시도')\n",
        "\n",
        "\n",
        "out = r\"C:\\Users\\zkdlt\\Desktop\\SK_ASAC\\project\\good\\판사들에 따라 지역에서 동일조건에 대한 심급편차.xlsx\"\n",
        "with pd.ExcelWriter(out, engine='openpyxl') as xw:\n",
        "    # 차이 ‘있는’ 행만: 태블로 바로 투입\n",
        "    권역_편차.to_excel(xw, sheet_name='권역_편차(차이있음)', index=False)\n",
        "    시도_편차.to_excel(xw, sheet_name='시도_편차(차이있음)', index=False)\n",
        "    # 참고: 심급별 원지표(필요시)\n",
        "    권역_심급지표.to_excel(xw, sheet_name='권역_심급지표(참고)', index=False)\n",
        "    시도_심급지표.to_excel(xw, sheet_name='시도_심급지표(참고)', index=False)\n",
        "\n",
        "print(\"저장 완료 →\", out)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 동일조건 심급별 항소 및 감형 편차\n",
        "\n",
        "\n",
        "df = df.copy()\n",
        "\n",
        "\n",
        "df['판사명'] = df['판사명'].astype(str).str.strip()\n",
        "mask_bad = (\n",
        "    df['판사명'].isin({'', '판사미상'})\n",
        "    | df['판사명'].str.lower().isin({'nan','none'})\n",
        "    | df['판사명'].str.contains(r'(성명\\s*생략|기재\\s*생략|미상)$', na=False)\n",
        ")\n",
        "df = df.loc[~mask_bad].reset_index(drop=True)\n",
        "\n",
        "\n",
        "df['심급'] = df['심급'].fillna('1심').astype(str)\n",
        "df['법원_권역'] = df['법원_권역'].fillna('기타')\n",
        "df['시도'] = df['시도'].fillna('미상')\n",
        "\n",
        "\n",
        "kw = df.explode('범죄키워드_리스트').rename(columns={'범죄키워드_리스트':'키워드'})\n",
        "kw = kw[kw['키워드'].astype(str).str.strip().ne('')]\n",
        "kw = kw[~kw['키워드'].astype(str).str.lower().isin({'nan','none','null'})]\n",
        "\n",
        "\n",
        "kw['조건'] = np.where(kw['초범여부'].fillna(False), '초범',\n",
        "               np.where(kw['재범여부'].fillna(False), '재범', '불명'))\n",
        "\n",
        "\n",
        "kw['항소'] = kw['상소여부'].fillna(False).astype(bool)\n",
        "kw['감형'] = kw['감형사건_광의'].fillna(False).astype(bool)   # 필요시 _보수 로 바꿔도 됨\n",
        "\n",
        "# 권역/시도별 “동일조건” 편차 계산 함수 -------------------------\n",
        "MIN_N = 5       # 각 지역 조합 최소 사건수\n",
        "MIN_DIFF = 0.0  # 편차 하한(예: 0.05로 두면 5%p 이상 차이만 남김)\n",
        "\n",
        "def region_diff(region_col: str):\n",
        "    # (심급, 지역, 키워드, 조건)별 사건수/항소율/감형율\n",
        "    agg = (kw.groupby(['심급', region_col, '키워드', '조건'], observed=True)\n",
        "             .agg(사건수=('키워드','size'),\n",
        "                  항소건수=('항소','sum'),\n",
        "                  감형건수=('감형','sum'))\n",
        "             .reset_index())\n",
        "    # 최소 사건수 필터\n",
        "    agg = agg.loc[agg['사건수'] >= MIN_N].copy()\n",
        "    if agg.empty:\n",
        "        return agg, agg  # 빈 결과\n",
        "\n",
        "    agg['항소율'] = agg['항소건수'] / agg['사건수']\n",
        "    agg['감형율'] = agg['감형건수'] / agg['사건수']\n",
        "\n",
        "    # 동일조건(심급+키워드+조건) 안에서 지역 간 min/max 및 편차\n",
        "    key = ['심급','키워드','조건']\n",
        "    span = (agg.groupby(key, observed=True)\n",
        "              .agg(항소율_min=('항소율','min'), 항소율_max=('항소율','max'),\n",
        "                   감형율_min=('감형율','min'), 감형율_max=('감형율','max'))\n",
        "              .reset_index())\n",
        "    span['항소율_편차'] = span['항소율_max'] - span['항소율_min']\n",
        "    span['감형율_편차'] = span['감형율_max'] - span['감형율_min']\n",
        "\n",
        "    # 편차가 있는 조합만\n",
        "    span = span.query(\"(항소율_편차 > @MIN_DIFF) or (감형율_편차 > @MIN_DIFF)\").copy()\n",
        "    if span.empty:\n",
        "        return agg, span\n",
        "\n",
        "    # 편차의 주체(최소/최대 지역) 붙이기\n",
        "    idx_min_항 = (agg.sort_values('항소율')\n",
        "                    .groupby(key, observed=True).head(1)\n",
        "                    [key + [region_col]].rename(columns={region_col:'항소율_min_지역'}))\n",
        "    idx_max_항 = (agg.sort_values('항소율', ascending=False)\n",
        "                    .groupby(key, observed=True).head(1)\n",
        "                    [key + [region_col]].rename(columns={region_col:'항소율_max_지역'}))\n",
        "    idx_min_감 = (agg.sort_values('감형율')\n",
        "                    .groupby(key, observed=True).head(1)\n",
        "                    [key + [region_col]].rename(columns={region_col:'감형율_min_지역'}))\n",
        "    idx_max_감 = (agg.sort_values('감형율', ascending=False)\n",
        "                    .groupby(key, observed=True).head(1)\n",
        "                    [key + [region_col]].rename(columns={region_col:'감형율_max_지역'}))\n",
        "\n",
        "    span = (span.merge(idx_min_항, on=key)\n",
        "                .merge(idx_max_항, on=key)\n",
        "                .merge(idx_min_감, on=key)\n",
        "                .merge(idx_max_감, on=key)\n",
        "                .sort_values(['심급','항소율_편차','감형율_편차'], ascending=[True, False, False]))\n",
        "    return agg, span\n",
        "\n",
        "\n",
        "권역_세부, 권역_편차요약 = region_diff('법원_권역')\n",
        "시도_세부, 시도_편차요약 = region_diff('시도')\n",
        "\n",
        "\n",
        "out = r\"C:\\Users\\zkdlt\\Desktop\\SK_ASAC\\project\\good\\권역별_동일조건_심급_항소감형편차(판사명 없음).xlsx\"\n",
        "with pd.ExcelWriter(out, engine='openpyxl') as xw:\n",
        "    권역_세부.to_excel(xw, sheet_name='권역_세부(율포함)', index=False)\n",
        "    권역_편차요약.to_excel(xw, sheet_name='권역_편차요약', index=False)\n",
        "    시도_세부.to_excel(xw, sheet_name='시도_세부(율포함)', index=False)\n",
        "    시도_편차요약.to_excel(xw, sheet_name='시도_편차요약', index=False)\n",
        "print(\"저장:\", out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저장 완료 → C:\\Users\\zkdlt\\Desktop\\SK_ASAC\\project\\good\\지역형량편차.xlsx\n"
          ]
        }
      ],
      "source": [
        "# 3. 지역별 형량 편차 동일한 조건의 범죄일 경우 수도권 vs 지방, \n",
        "#       광역시 vs 도 단위 형량 차이 분석 지역간의 성격\n",
        "\n",
        "\n",
        "\n",
        "df2 = df.copy()\n",
        "\n",
        "# 판사미상/생략 제거\n",
        "df2['판사명'] = df2['판사명'].astype(str)\n",
        "bad_judge = (\n",
        "    df2['판사명'].isna() |\n",
        "    df2['판사명'].str.strip().eq('') |\n",
        "    df2['판사명'].str.lower().isin({'nan','none'}) |\n",
        "    df2['판사명'].str.contains('미상|생략', na=False) |\n",
        "    df2['판사명'].eq('판사미상')\n",
        ")\n",
        "df2 = df2[~bad_judge].copy()\n",
        "\n",
        "# 꼭 쓰는 컬럼 결측 보정\n",
        "df2['심급'] = df2['심급'].fillna('1심').astype(str)\n",
        "df2['시도'] = df2['시도'].fillna('미상').astype(str)\n",
        "df2['법원_권역'] = df2['법원_권역'].fillna('기타').astype(str)\n",
        "df2['선고유형_대분류'] = df2.get('선고유형_대분류', '기타')\n",
        "df2['형량_월_기준'] = pd.to_numeric(df2.get('형량_월_기준', 0), errors='coerce').fillna(0)\n",
        "\n",
        "# 항소/감형 플래그 없으면 기본 0 (False)\n",
        "for col in ['상소여부', '감형사건_광의']:\n",
        "    if col not in df2.columns:\n",
        "        df2[col] = False\n",
        "df2['상소여부'] = df2['상소여부'].astype(bool)\n",
        "df2['감형사건_광의'] = df2['감형사건_광의'].astype(bool)\n",
        "\n",
        "# 지역 비교축 만들기\n",
        "# - 수도권 vs 지방: 수도권(서울/인천/경기), 그 외는 지방\n",
        "metro = {'서울특별시','인천광역시','경기도'}\n",
        "df2['수도권vs지방'] = np.where(df2['시도'].isin(metro), '수도권', '지방')\n",
        "\n",
        "# - 광역시 vs 도: 특/광역시(서울·인천·부산·대구·광주·대전·울산·세종·제주) vs 도(경기·강원특별자치도·충북·충남·전북·전남·경북·경남)\n",
        "metro2 = {'서울특별시','인천광역시','부산광역시','대구광역시','광주광역시','대전광역시','울산광역시','세종특별자치시','제주특별자치도'}\n",
        "df2['광역시vs도'] = np.where(df2['시도'].isin(metro2), '특/광역시', '도')\n",
        "\n",
        "# “주요키워드” (동일조건의 최소 단위) — 첫 키워드 하나만 사용\n",
        "def ensure_list(v):\n",
        "    if isinstance(v, list): return v\n",
        "    if pd.isna(v) or v is None: return []\n",
        "    return [v]\n",
        "df2['범죄키워드_리스트'] = df2['범죄키워드_리스트'].apply(ensure_list)\n",
        "df2['주요키워드'] = df2['범죄키워드_리스트'].apply(lambda L: (L[0] if L else '미상'))\n",
        "\n",
        "\n",
        "# 동일조건(예시): 심급 + 주요키워드  → 필요시 초범여부 등 컬럼을 +로 늘리면 됨\n",
        "cond_cols = ['심급','주요키워드']\n",
        "\n",
        "def compare_by(df_src, compare_col, left_label, right_label, cond_cols):\n",
        "    # 비교 집단만 사용\n",
        "    use = df_src[df_src[compare_col].isin([left_label, right_label])].copy()\n",
        "\n",
        "    base = (use\n",
        "            .groupby(cond_cols + [compare_col], observed=True)\n",
        "            .agg(\n",
        "                사건수=('형량_월_기준','size'),\n",
        "                평균형량=('형량_월_기준','mean'),\n",
        "                항소율=('상소여부','mean'),\n",
        "                감형율=('감형사건_광의','mean')\n",
        "            ).reset_index())\n",
        "\n",
        "    # 기초 인덱스: 동일조건 고유 조합으로 시작\n",
        "    out = base[cond_cols].drop_duplicates().reset_index(drop=True).copy()\n",
        "\n",
        "    metrics = ['사건수','평균형량','항소율','감형율']\n",
        "    for m in metrics:\n",
        "        w = (base.pivot_table(index=cond_cols, columns=compare_col, values=m, fill_value=np.nan)\n",
        "                 .rename(columns={\n",
        "                     left_label:  f'{m}_좌({left_label})',\n",
        "                     right_label: f'{m}_우({right_label})'\n",
        "                 })\n",
        "                 .reset_index())\n",
        "\n",
        "        # 한쪽 집단이 아예 없을 때 대비\n",
        "        lcol = f'{m}_좌({left_label})'\n",
        "        rcol = f'{m}_우({right_label})'\n",
        "        if lcol not in w.columns: w[lcol] = np.nan\n",
        "        if rcol not in w.columns: w[rcol] = np.nan\n",
        "\n",
        "        # 차이(좌-우)\n",
        "        w[f'{m}_차이(좌-우)'] = w[lcol] - w[rcol]\n",
        "\n",
        "        # 누적 병합\n",
        "        out = out.merge(w, on=cond_cols, how='left')\n",
        "\n",
        "    out.insert(0, '비교유형', compare_col)\n",
        "    out.insert(1, '좌라벨', left_label)\n",
        "    out.insert(2, '우라벨', right_label)\n",
        "    return out\n",
        "\n",
        "\n",
        "met_수지 = compare_by(df2, '수도권vs지방', '수도권', '지방', cond_cols)\n",
        "met_광도 = compare_by(df2, '광역시vs도',   '특/광역시', '도', cond_cols)\n",
        "met = pd.concat([met_수지, met_광도], ignore_index=True)\n",
        "\n",
        "\n",
        "def composition_by(df_src, compare_col, left_label, right_label, cond_cols, topk=5):\n",
        "    use = df_src[df_src[compare_col].isin([left_label, right_label])].copy()\n",
        "\n",
        "    # 선고유형 구성\n",
        "    sent = (use.groupby(cond_cols + [compare_col,'선고유형_대분류'], observed=True)\n",
        "            .size().rename('건수').reset_index())\n",
        "    tot_sent = (sent.groupby(cond_cols + [compare_col], observed=True)['건수']\n",
        "                     .sum().rename('총건수')).reset_index()\n",
        "    sent = sent.merge(tot_sent, on=cond_cols + [compare_col], how='left')\n",
        "    sent['값'] = sent['건수'] / sent['총건수'].replace(0, np.nan)\n",
        "    sent = sent.rename(columns={'선고유형_대분류':'항목'})\n",
        "    sent['지표'] = '선고유형구성'\n",
        "    sent = sent.drop(columns=['건수','총건수'])\n",
        "\n",
        "    # 키워드 구성 — 분모는 “전체 키워드 총합”\n",
        "    kw = (use.explode('범죄키워드_리스트')\n",
        "              .rename(columns={'범죄키워드_리스트':'키워드'}))\n",
        "    kw = kw[kw['키워드'].astype(str).str.strip().ne('')]\n",
        "    kw = kw[~kw['키워드'].astype(str).str.lower().isin({'nan','none','null'})]\n",
        "\n",
        "    kw_all = (kw.groupby(cond_cols + [compare_col, '키워드'], observed=True)\n",
        "                .size().rename('건수').reset_index())\n",
        "    tot_kw = (kw_all.groupby(cond_cols + [compare_col], observed=True)['건수']\n",
        "                   .sum().rename('키워드총합')).reset_index()\n",
        "    kw_all = kw_all.merge(tot_kw, on=cond_cols + [compare_col], how='left')\n",
        "    kw_all['값'] = kw_all['건수'] / kw_all['키워드총합'].replace(0, np.nan)\n",
        "\n",
        "    # TOP-k만 표시용으로 컷(각 조건×비교군별)\n",
        "    kw_all['rk'] = kw_all.groupby(cond_cols + [compare_col])['건수'].rank(method='first', ascending=False)\n",
        "    kw_top = (kw_all[kw_all['rk'] <= topk]\n",
        "              .rename(columns={'키워드':'항목'})\n",
        "              .drop(columns=['건수','키워드총합','rk']))\n",
        "    kw_top['지표'] = f'키워드구성(TOP{topk})'\n",
        "\n",
        "    comp = pd.concat([sent, kw_top], ignore_index=True)\n",
        "    comp.insert(0, '비교유형', compare_col)\n",
        "    comp.insert(1, '좌라벨', left_label)\n",
        "    comp.insert(2, '우라벨', right_label)\n",
        "    return comp\n",
        "\n",
        "g_수지 = composition_by(df2, '수도권vs지방', '수도권', '지방', cond_cols, topk=5)\n",
        "g_광도 = composition_by(df2, '광역시vs도',   '특/광역시', '도', cond_cols, topk=5)\n",
        "g = pd.concat([g_수지, g_광도], ignore_index=True)\n",
        "\n",
        "# 엑셀로 저장(태블로 투입) — 비교축 분리 시트 \n",
        "out_path = r\"C:\\Users\\zkdlt\\Desktop\\SK_ASAC\\project\\good\\지역형량편차.xlsx\"\n",
        "with pd.ExcelWriter(out_path, engine='openpyxl') as xw:\n",
        "    met.query(\"비교유형 == '수도권vs지방'\").to_excel(xw, sheet_name='편차_수도권vs지방', index=False)\n",
        "    met.query(\"비교유형 == '광역시vs도'\").to_excel(xw, sheet_name='편차_광역시vs도', index=False)\n",
        "    g.query(\"비교유형 == '수도권vs지방'\").to_excel(xw, sheet_name='구성_수도권vs지방', index=False)\n",
        "    g.query(\"비교유형 == '광역시vs도'\").to_excel(xw, sheet_name='구성_광역시vs도', index=False)\n",
        "\n",
        "print(\"저장 완료 →\", out_path)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[저장완료] 폴더: C:\\Users\\zkdlt\\Desktop\\SK_ASAC\\project\\good\n"
          ]
        }
      ],
      "source": [
        "# 4. 항소여부 vs 감형 확율 항소가 실제로 감형으로 이어지는걸 \n",
        "#       검증 항소을 했을때 감형되는 텍스트 키워드 1위부터 5위까지 나타내기\n",
        "#       그리고 감형율이 높은 지역이 어디인지 그리고 감형을 해주는 범죄키워드가 무엇인지도 \n",
        "#       조사해야해 항소 결과에 따른 감형 또는 기각 그 사유별도 분석\n",
        "\n",
        "\n",
        "PATH = Path(r\"C:\\Users\\zkdlt\\Desktop\\SK_ASAC\\project\\good\")\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 컬럼 안전보정 (최소한만)\n",
        "if df['상소여부'].dtype != bool:\n",
        "    df['상소여부'] = df['상소여부'].astype(str).isin(['True','1','예','Y','y','true','상소','항소','2심','3심'])\n",
        "if '감형여부' not in df.columns:\n",
        "    df['감형여부'] = df.get('감형사건_광의', False).fillna(False).astype(bool)\n",
        "df['범죄키워드_리스트'] = df.get('범죄키워드_리스트', []).apply(lambda v: v if isinstance(v, list) else ([] if pd.isna(v) else [v]))\n",
        "df['본문_정규화'] = df.get('본문_정규화','').fillna('').astype(str)\n",
        "\n",
        "# 사건ID\n",
        "df['사건ID'] = (df['사건번호'].astype(str) if '사건번호' in df.columns else df.index.astype(str))\n",
        "\n",
        "# 지역(시도/권역)별 '항소율' + '항소 사건 감형율'\n",
        "(_df:=df.copy())\n",
        "(_a:=_df[_df['상소여부']])\n",
        "\n",
        "sido_appeal = (_df.groupby('시도')['상소여부']\n",
        "                 .agg(전체사건수='size', 항소사건수='sum')\n",
        "                 .assign(**{'항소율(%)': lambda d: (d['항소사건수']/d['전체사건수']*100).round(2)}))\n",
        "sido_len = (_a.groupby('시도')['감형여부']\n",
        "              .agg(항소_사건수='size', 항소_감형건수='sum')\n",
        "              .assign(**{'항소_감형율(%)': lambda d: (d['항소_감형건수']/d['항소_사건수']*100).round(2)}))\n",
        "sido_summary = (sido_appeal.reset_index()\n",
        "                          .merge(sido_len.reset_index(), on='시도', how='left')\n",
        "                          .sort_values(['항소_감형율(%)','항소_사건수'], ascending=[False,False]))\n",
        "sido_summary.to_csv(PATH/\"지역요약_시도_항소율_및_항소감형율.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "region_appeal = (_df.groupby('법원_권역')['상소여부']\n",
        "                   .agg(전체사건수='size', 항소사건수='sum')\n",
        "                   .assign(**{'항소율(%)': lambda d: (d['항소사건수']/d['전체사건수']*100).round(2)}))\n",
        "region_len = (_a.groupby('법원_권역')['감형여부']\n",
        "                .agg(항소_사건수='size', 항소_감형건수='sum')\n",
        "                .assign(**{'항소_감형율(%)': lambda d: (d['항소_감형건수']/d['항소_사건수']*100).round(2)}))\n",
        "region_summary = (region_appeal.reset_index()\n",
        "                              .merge(region_len.reset_index(), on='법원_권역', how='left')\n",
        "                              .sort_values(['항소_감형율(%)','항소_사건수'], ascending=[False,False]))\n",
        "region_summary.to_csv(PATH/\"지역요약_권역_항소율_및_항소감형율.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# 지역별(항소 사건 기준) 감형율\n",
        "(_a.groupby('시도')['감형여부']\n",
        "   .agg(사건수='size', 감형건수='sum')\n",
        "   .assign(**{'감형율(%)': lambda d:(d['감형건수']/d['사건수']*100).round(2)}))\\\n",
        "  .reset_index()\\\n",
        "  .sort_values(['감형율(%)','사건수'], ascending=[False,False])\\\n",
        "  .to_csv(PATH/\"시도별_감형율.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "(_a.groupby('법원_권역')['감형여부']\n",
        "   .agg(사건수='size', 감형건수='sum')\n",
        "   .assign(**{'감형율(%)': lambda d:(d['감형건수']/d['사건수']*100).round(2)}))\\\n",
        "  .reset_index()\\\n",
        "  .sort_values(['감형율(%)','사건수'], ascending=[False,False])\\\n",
        "  .to_csv(PATH/\"권역별_감형율.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# 지역×범죄키워드 감형율(항소 사건 기준) — 태블로 피벗/필터용\n",
        "(_a[['시도','법원_권역','감형여부','범죄키워드_리스트']]\n",
        "   .explode('범죄키워드_리스트')\n",
        "   .rename(columns={'범죄키워드_리스트':'범죄키워드'})\n",
        "   .query(\"범죄키워드.str.strip() != ''\", engine='python')\n",
        "   .groupby(['시도','범죄키워드'])['감형여부']\n",
        "   .agg(사건수='size', 감형건수='sum')\n",
        "   .assign(**{'감형율(%)': lambda d:(d['감형건수']/d['사건수']*100).round(2)}))\\\n",
        "  .reset_index().to_csv(PATH/\"시도별_범죄키워드별_감형율.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "(_a[['시도','법원_권역','감형여부','범죄키워드_리스트']]\n",
        "   .explode('범죄키워드_리스트')\n",
        "   .rename(columns={'범죄키워드_리스트':'범죄키워드'})\n",
        "   .query(\"범죄키워드.str.strip() != ''\", engine='python')\n",
        "   .groupby(['법원_권역','범죄키워드'])['감형여부']\n",
        "   .agg(사건수='size', 감형건수='sum')\n",
        "   .assign(**{'감형율(%)': lambda d:(d['감형건수']/d['사건수']*100).round(2)}))\\\n",
        "  .reset_index().to_csv(PATH/\"권역별_범죄키워드별_감형율.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# 지역별(항소&감형 사건) 텍스트 사유 Top5\n",
        "REASONS = ['양형부당','법리오해','사실오인','심리미진','양형조건','정상참작','참작사유',\n",
        "           '과중','부당','감형','감경','공제','상계','원심파기','원심유지','원심변경',\n",
        "           '합의','반성','초범','누범','상습','동종전과','사회봉사','수강명령','유리한정상','불리한정상']\n",
        "pat = re.compile('|'.join(map(re.escape, REASONS)))\n",
        "(_a[_a['감형여부']]\n",
        "   .assign(키워드리스트=lambda d: d['본문_정규화'].str.findall(pat))\n",
        "   .explode('키워드리스트')\n",
        "   .dropna(subset=['키워드리스트'])\n",
        "   .groupby(['시도','키워드리스트'])\n",
        "   .size().rename('건수').reset_index()\n",
        "   .sort_values(['시도','건수'], ascending=[True,False])\n",
        "   .groupby('시도').head(5)\n",
        "   .rename(columns={'키워드리스트':'키워드'}))\\\n",
        "  .to_csv(PATH/\"시도별_감형유도_텍스트Top5.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "(_a[_a['감형여부']]\n",
        "   .assign(키워드리스트=lambda d: d['본문_정규화'].str.findall(pat))\n",
        "   .explode('키워드리스트')\n",
        "   .dropna(subset=['키워드리스트'])\n",
        "   .groupby(['법원_권역','키워드리스트'])\n",
        "   .size().rename('건수').reset_index()\n",
        "   .sort_values(['법원_권역','건수'], ascending=[True,False])\n",
        "   .groupby('법원_권역').head(5)\n",
        "   .rename(columns={'키워드리스트':'키워드'}))\\\n",
        "  .to_csv(PATH/\"권역별_감형유도_텍스트Top5.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# 동일범죄 기준: 형량편차(전국평균 대비) + 항소감형 과다/낮음 의심\n",
        "# 형량편차(월) — 범죄키워드×지역 평균 vs 전국 평균\n",
        "nat = (df[['형량_월_기준','범죄키워드_리스트']]\n",
        "         .explode('범죄키워드_리스트')\n",
        "         .rename(columns={'범죄키워드_리스트':'범죄키워드'})\n",
        "         .query(\"범죄키워드.str.strip() != ''\", engine='python')\n",
        "         .groupby('범죄키워드')['형량_월_기준'].mean()\n",
        "         .rename('전국평균형량').round(2))\n",
        "\n",
        "(df[['시도','법원_권역','형량_월_기준','범죄키워드_리스트']]\n",
        "   .explode('범죄키워드_리스트')\n",
        "   .rename(columns={'범죄키워드_리스트':'범죄키워드'})\n",
        "   .query(\"범죄키워드.str.strip() != ''\", engine='python')\n",
        "   .groupby(['범죄키워드','시도'])['형량_월_기준']\n",
        "   .agg(사건수='size', 평균형량='mean', 중앙형량='median').round(2).reset_index()\n",
        "   .merge(nat.reset_index(), on='범죄키워드', how='left')\n",
        "   .assign(**{'전국대비_편차(월)': lambda d: (d['평균형량']-d['전국평균형량']).round(2)}))\\\n",
        "  .sort_values(['범죄키워드','전국대비_편차(월)','사건수'], ascending=[True,True,False])\\\n",
        "  .to_csv(PATH/\"동일범죄_시도별_형량편차.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "(df[['시도','법원_권역','형량_월_기준','범죄키워드_리스트']]\n",
        "   .explode('범죄키워드_리스트')\n",
        "   .rename(columns={'범죄키워드_리스트':'범죄키워드'})\n",
        "   .query(\"범죄키워드.str.strip() != ''\", engine='python')\n",
        "   .groupby(['범죄키워드','법원_권역'])['형량_월_기준']\n",
        "   .agg(사건수='size', 평균형량='mean', 중앙형량='median').round(2).reset_index()\n",
        "   .merge(nat.reset_index(), on='범죄키워드', how='left')\n",
        "   .assign(**{'전국대비_편차(월)': lambda d: (d['평균형량']-d['전국평균형량']).round(2)}))\\\n",
        "  .sort_values(['범죄키워드','전국대비_편차(월)','사건수'], ascending=[True,True,False])\\\n",
        "  .to_csv(PATH/\"동일범죄_권역별_형량편차.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# 항소감형 과다/낮음 의심 (전국 대비 ±5%p, 표본≥30)\n",
        "nat_len = round((_a['감형여부'].mean()*100) if len(_a) else np.nan, 2)\n",
        "flag_params = {'표본최소':30, '임계(%p)':5.0}\n",
        "\n",
        "(region_summary\n",
        "   .assign(**{\n",
        "       '전국_항소감형율(%)': nat_len,\n",
        "       '전국대비_차이(%p)': lambda d: (d['항소_감형율(%)']-d['전국_항소감형율(%)']).round(2),\n",
        "       '표본충분': lambda d: d['항소_사건수']>=flag_params['표본최소'],\n",
        "       '항소감형_과다의심': lambda d: d['표본충분'] & (d['전국대비_차이(%p)']>=flag_params['임계(%p)']),\n",
        "       '항소감형_낮음의심': lambda d: d['표본충분'] & (d['전국대비_차이(%p)']<=-flag_params['임계(%p)'])\n",
        "   }))\\\n",
        "  .to_csv(PATH/\"공정성_권역별_항소감형_의심표.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "(sido_summary\n",
        "   .assign(**{\n",
        "       '전국_항소감형율(%)': nat_len,\n",
        "       '전국대비_차이(%p)': lambda d: (d['항소_감형율(%)']-d['전국_항소감형율(%)']).round(2),\n",
        "       '표본충분': lambda d: d['항소_사건수']>=flag_params['표본최소'],\n",
        "       '항소감형_과다의심': lambda d: d['표본충분'] & (d['전국대비_차이(%p)']>=flag_params['임계(%p)']),\n",
        "       '항소감형_낮음의심': lambda d: d['표본충분'] & (d['전국대비_차이(%p)']<=-flag_params['임계(%p)'])\n",
        "   }))\\\n",
        "  .to_csv(PATH/\"공정성_시도별_항소감형_의심표.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# 태블로 팩트(사건×키워드) + 텍스트사유(사건×키워드)\n",
        "(df[['사건ID','선고일','선고연도','선고분기','법원명','시도','법원_권역','심급',\n",
        "      '상소여부','감형여부','상소결과_대분류','형량_월_기준','선고유형_대분류',\n",
        "      '징역_월','금고_월','집행유예','벌금_원','범죄키워드_리스트']]\n",
        "   .explode('범죄키워드_리스트').rename(columns={'범죄키워드_리스트':'범죄키워드'})\n",
        "   .query(\"범죄키워드.str.strip() != ''\", engine='python'))\\\n",
        "  .to_csv(PATH/\"tableau_fact_cases_long.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "(txt:=df['본문_정규화'].str.findall(pat))  # 재사용\n",
        "(pd.DataFrame({\n",
        "    '사건ID': df['사건ID'].repeat(txt.str.len().fillna(0).astype(int)),\n",
        "    '시도': df['시도'].repeat(txt.str.len().fillna(0).astype(int)),\n",
        "    '법원_권역': df['법원_권역'].repeat(txt.str.len().fillna(0).astype(int)),\n",
        "    '상소여부': df['상소여부'].repeat(txt.str.len().fillna(0).astype(int)),\n",
        "    '감형여부': df['감형여부'].repeat(txt.str.len().fillna(0).astype(int)),\n",
        "    '상소결과_대분류': df.get('상소결과_대분류', pd.Series(['']*len(df))).repeat(txt.str.len().fillna(0).astype(int)),\n",
        "    '사유키워드': txt.explode().dropna()\n",
        "}).query(\"사유키워드.str.strip() != ''\", engine='python'))\\\n",
        " .assign(존재=1)\\\n",
        " .to_csv(PATH/\"tableau_reasons_long.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"[저장완료] 폴더:\", PATH)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결론\n",
        "#    - 지역별 사법 문화 차이\n",
        "# **한계**: 법 그 자체의 허점인지, 판사 재량 문제인지 구분이 어려움 분석\n",
        "\n",
        "# 이 내용은 최종적으로 결론의 그냥 글귀로 구사해야할듯?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
